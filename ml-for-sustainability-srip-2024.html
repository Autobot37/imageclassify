<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>imageclassify - ML for Sustainability</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="imageclassify - ML for Sustainability">
<meta property="og:description" content="large scale">
<meta property="og:site_name" content="imageclassify">
<meta name="twitter:title" content="imageclassify - ML for Sustainability">
<meta name="twitter:description" content="large scale">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">imageclassify</span>
    </a>
  </div>
        <div class="quarto-navbar-tools">
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ml-for-sustainability-srip-2024.html">ML for Sustainability</a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Readme</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ml-for-sustainability-srip-2024.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">ML for Sustainability</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#data-utilities" id="toc-data-utilities" class="nav-link active" data-scroll-target="#data-utilities">Data Utilities</a></li>
  <li><a href="#here-is-mean-data-distribution-of-pixel-values-of-all-classes" id="toc-here-is-mean-data-distribution-of-pixel-values-of-all-classes" class="nav-link" data-scroll-target="#here-is-mean-data-distribution-of-pixel-values-of-all-classes">Here is mean data distribution of pixel values of all classes</a></li>
  <li><a href="#train-function" id="toc-train-function" class="nav-link" data-scroll-target="#train-function">Train function</a></li>
  <li><a href="#main-one-vs-rest-binary-classification-function" id="toc-main-one-vs-rest-binary-classification-function" class="nav-link" data-scroll-target="#main-one-vs-rest-binary-classification-function">Main One vs Rest binary classification function</a></li>
  <li><a href="#dataloader" id="toc-dataloader" class="nav-link" data-scroll-target="#dataloader">Dataloader</a></li>
  <li><a href="#custommodel" id="toc-custommodel" class="nav-link" data-scroll-target="#custommodel">CustomModel</a></li>
  <li><a href="#components" id="toc-components" class="nav-link" data-scroll-target="#components"><em>Components</em></a></li>
  <li><a href="#convolution-blocks" id="toc-convolution-blocks" class="nav-link" data-scroll-target="#convolution-blocks">Convolution Blocks</a></li>
  <li><a href="#hyperparameters" id="toc-hyperparameters" class="nav-link" data-scroll-target="#hyperparameters">Hyperparameters</a>
  <ul class="collapse">
  <li><a href="#attention-block" id="toc-attention-block" class="nav-link" data-scroll-target="#attention-block">Attention Block</a></li>
  <li><a href="#initialising" id="toc-initialising" class="nav-link" data-scroll-target="#initialising">Initialising</a></li>
  <li><a href="#now-we-just-for-every-data-class-perform-one-vs-rest-classification-for" id="toc-now-we-just-for-every-data-class-perform-one-vs-rest-classification-for" class="nav-link" data-scroll-target="#now-we-just-for-every-data-class-perform-one-vs-rest-classification-for">Now we just for every data class perform One vs Rest classification for :</a></li>
  <li><a href="#note-i-am-currently-performing-for-only-5-selected-class-due-to-compute-unavailability-and-kaggle-gpu-just-stucks-after-some-hours." id="toc-note-i-am-currently-performing-for-only-5-selected-class-due-to-compute-unavailability-and-kaggle-gpu-just-stucks-after-some-hours." class="nav-link" data-scroll-target="#note-i-am-currently-performing-for-only-5-selected-class-due-to-compute-unavailability-and-kaggle-gpu-just-stucks-after-some-hours.">|Note : i am currently performing for only 5 selected class, due to compute unavailability and kaggle GPU just stucks after some hours.</a></li>
  </ul></li>
  <li><a href="#resnet" id="toc-resnet" class="nav-link" data-scroll-target="#resnet">Resnet</a>
  <ul class="collapse">
  <li><a href="#since-90-classes-are-lot-we-will-plot-foldwise-mean-of-loss-accuracy-and-confusion-matrix-for-all-classes" id="toc-since-90-classes-are-lot-we-will-plot-foldwise-mean-of-loss-accuracy-and-confusion-matrix-for-all-classes" class="nav-link" data-scroll-target="#since-90-classes-are-lot-we-will-plot-foldwise-mean-of-loss-accuracy-and-confusion-matrix-for-all-classes">Since 90 classes are lot, we will plot foldwise mean of loss accuracy and confusion matrix for <strong>all classes</strong></a></li>
  <li><a href="#resnet-plots" id="toc-resnet-plots" class="nav-link" data-scroll-target="#resnet-plots">Resnet Plots</a></li>
  </ul></li>
  <li><a href="#efficientnet-b0" id="toc-efficientnet-b0" class="nav-link" data-scroll-target="#efficientnet-b0">EfficientNet b0</a></li>
  <li><a href="#efficientnet-plots" id="toc-efficientnet-plots" class="nav-link" data-scroll-target="#efficientnet-plots">EfficientNet Plots</a>
  <ul class="collapse">
  <li><a href="#custommodel-1" id="toc-custommodel-1" class="nav-link" data-scroll-target="#custommodel-1">CustomModel</a></li>
  </ul></li>
  <li><a href="#custommodel-plots" id="toc-custommodel-plots" class="nav-link" data-scroll-target="#custommodel-plots">CustomModel Plots</a>
  <ul class="collapse">
  <li><a href="#comparing-best-accuracy-on-validation" id="toc-comparing-best-accuracy-on-validation" class="nav-link" data-scroll-target="#comparing-best-accuracy-on-validation">Comparing Best Accuracy on Validation</a></li>
  </ul></li>
  <li><a href="#time-taken" id="toc-time-taken" class="nav-link" data-scroll-target="#time-taken">Time Taken</a></li>
  <li><a href="#five-class-classification" id="toc-five-class-classification" class="nav-link" data-scroll-target="#five-class-classification">Five class classification</a></li>
  <li><a href="#in-here-we-have-taken-5---5-classes-means-16-parts-of-90-class-dataset-each-containing-5-classes-and-perfomed-classification." id="toc-in-here-we-have-taken-5---5-classes-means-16-parts-of-90-class-dataset-each-containing-5-classes-and-perfomed-classification." class="nav-link" data-scroll-target="#in-here-we-have-taken-5---5-classes-means-16-parts-of-90-class-dataset-each-containing-5-classes-and-perfomed-classification.">in here, we have taken 5 - 5 classes, means 16 parts of 90 class dataset each containing 5 classes and perfomed classification.</a></li>
  <li><a href="#for-example-take-classes-05-then-perform-classification-then-510-etc." id="toc-for-example-take-classes-05-then-perform-classification-then-510-etc." class="nav-link" data-scroll-target="#for-example-take-classes-05-then-perform-classification-then-510-etc.">for example take classes [0,5) then perform classification then [5,10) etc.</a></li>
  <li><a href="#resnet-1" id="toc-resnet-1" class="nav-link" data-scroll-target="#resnet-1">Resnet</a></li>
  <li><a href="#resnet-plots-1" id="toc-resnet-plots-1" class="nav-link" data-scroll-target="#resnet-plots-1">Resnet Plots</a></li>
  <li><a href="#efficientnet" id="toc-efficientnet" class="nav-link" data-scroll-target="#efficientnet">EfficientNet</a></li>
  <li><a href="#efficientnet-plots-1" id="toc-efficientnet-plots-1" class="nav-link" data-scroll-target="#efficientnet-plots-1">EfficientNet Plots</a></li>
  <li><a href="#custommodel-2" id="toc-custommodel-2" class="nav-link" data-scroll-target="#custommodel-2">CustomModel</a></li>
  <li><a href="#custommodel-plots-1" id="toc-custommodel-plots-1" class="nav-link" data-scroll-target="#custommodel-plots-1">CustomModel Plots</a></li>
  <li><a href="#best-accuracy-on-validation" id="toc-best-accuracy-on-validation" class="nav-link" data-scroll-target="#best-accuracy-on-validation">Best Accuracy on Validation</a></li>
  <li><a href="#time-taken-1" id="toc-time-taken-1" class="nav-link" data-scroll-target="#time-taken-1">Time Taken</a></li>
  <li><a href="#visualising-neural-nets" id="toc-visualising-neural-nets" class="nav-link" data-scroll-target="#visualising-neural-nets">Visualising Neural Nets</a>
  <ul class="collapse">
  <li><a href="#visualising-customnet-attention-map" id="toc-visualising-customnet-attention-map" class="nav-link" data-scroll-target="#visualising-customnet-attention-map">Visualising CustomNet Attention Map</a></li>
  <li><a href="#visualing-convolution-output-of-layers" id="toc-visualing-convolution-output-of-layers" class="nav-link" data-scroll-target="#visualing-convolution-output-of-layers">Visualing Convolution Output of Layers</a></li>
  </ul></li>
  <li><a href="#resnet-2" id="toc-resnet-2" class="nav-link" data-scroll-target="#resnet-2">Resnet</a></li>
  <li><a href="#efficientnet-1" id="toc-efficientnet-1" class="nav-link" data-scroll-target="#efficientnet-1">EfficientNet</a>
  <ul class="collapse">
  <li><a href="#custommodel-3" id="toc-custommodel-3" class="nav-link" data-scroll-target="#custommodel-3">CustomModel</a></li>
  <li><a href="#double-descent-for-custommodel-performance" id="toc-double-descent-for-custommodel-performance" class="nav-link" data-scroll-target="#double-descent-for-custommodel-performance">Double Descent for custommodel performance</a></li>
  <li><a href="#layer-outputs" id="toc-layer-outputs" class="nav-link" data-scroll-target="#layer-outputs">layer outputs</a></li>
  </ul></li>
  <li><a href="#additional-refrences" id="toc-additional-refrences" class="nav-link" data-scroll-target="#additional-refrences">Additional Refrences</a></li>
  <li><a href="#httpsgithub.comautobot37machinelearningengine-for-training-code" id="toc-httpsgithub.comautobot37machinelearningengine-for-training-code" class="nav-link" data-scroll-target="#httpsgithub.comautobot37machinelearningengine-for-training-code">https://github.com/Autobot37/MachineLearningEngine for training code</a></li>
  <li><a href="#spcom2024-paperid204-code-i-am-2nd-author" id="toc-spcom2024-paperid204-code-i-am-2nd-author" class="nav-link" data-scroll-target="#spcom2024-paperid204-code-i-am-2nd-author">SPCOM2024 PaperID204 code [i am 2nd author]</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/Autobot37/imageclassify/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">ML for Sustainability</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<p><strong>Regular Imports</strong></p>
<div id="cell-3" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:29:40.549447Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:29:40.549080Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:29:44.214765Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:29:44.213965Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:29:40.549414Z&quot;}" data-trusted="true" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, roc_auc_score</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> transforms</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, SubsetRandomSampler</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> KFold</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, roc_auc_score</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.models <span class="im">as</span> models</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Specifying GPU for acceleration</strong></p>
<div id="cell-5" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:29:44.216554Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:29:44.216190Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:29:44.238738Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:29:44.237665Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:29:44.216530Z&quot;}" data-trusted="true" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="data-utilities" class="level2">
<h2 class="anchored" data-anchor-id="data-utilities">Data Utilities</h2>
<ul>
<li>data augmentation and transforms to prevent overfitting with eg random flip.</li>
<li>image size we resizing is (224,224,3)</li>
<li>normalising to a mean and standard deviation i specifically choose this mean because this is mean and std from imagenet dataset and a good representative for image datasets. [(https://stackoverflow.com/questions/58151507/why-pytorch-officially-use-mean-0-485-0-456-0-406-and-std-0-229-0-224-0-2)]</li>
</ul>
<div id="cell-7" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:29:44.240427Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:29:44.240058Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:29:44.250793Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:29:44.249907Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:29:44.240392Z&quot;}" data-trusted="true" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Data(torch.utils.data.Dataset):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,images,labels):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.images <span class="op">=</span> images</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.labels <span class="op">=</span> labels</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.preprocess <span class="op">=</span> transforms.Compose([</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>            transforms.RandomHorizontalFlip(),</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>            transforms.Resize(<span class="dv">256</span>),</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>            transforms.CenterCrop(<span class="dv">224</span>),</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>            transforms.ToTensor(),</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>            transforms.Normalize(mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>], std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]),</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">assert</span> <span class="bu">len</span>(<span class="va">self</span>.images)<span class="op">==</span><span class="bu">len</span>(<span class="va">self</span>.labels),<span class="st">"unmatched dataset"</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.images)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>,idx):</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        img <span class="op">=</span> Image.<span class="bu">open</span>(<span class="va">self</span>.images[idx])</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="va">self</span>.labels[idx]</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.preprocess(img), torch.tensor(label,dtype<span class="op">=</span>torch.<span class="bu">long</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="here-is-mean-data-distribution-of-pixel-values-of-all-classes" class="level2">
<h2 class="anchored" data-anchor-id="here-is-mean-data-distribution-of-pixel-values-of-all-classes">Here is mean data distribution of pixel values of all classes</h2>
<div id="cell-9" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:29:44.253192Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:29:44.252818Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:30:27.388201Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:30:27.387264Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:29:44.253167Z&quot;}" data-trusted="true" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>img_path <span class="op">=</span> <span class="st">"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals"</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>pixel_values <span class="op">=</span> []</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>images <span class="op">=</span> []</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> folder <span class="kw">in</span> os.listdir(img_path):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    anim_fold <span class="op">=</span> os.path.join(img_path, folder)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t, img_file <span class="kw">in</span> <span class="bu">enumerate</span>(os.listdir(anim_fold)):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> t<span class="op">&gt;=</span><span class="dv">1</span>:<span class="cf">break</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        img_path_full <span class="op">=</span> os.path.join(anim_fold, img_file)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        images.append(img_path_full)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>labels <span class="op">=</span> [<span class="op">-</span><span class="dv">1</span>]<span class="op">*</span><span class="bu">len</span>(images)</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>temp_data <span class="op">=</span> Data(images<span class="op">=</span>images,labels<span class="op">=</span>labels)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> img,label <span class="kw">in</span> temp_data:</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    pixel_values.append(img.flatten())</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot histogram of pixel values</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>plt.hist(pixel_values, bins<span class="op">=</span><span class="dv">30</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Pixel Value'</span>)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Histogram of Pixel Values'</span>)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="train-function" class="level2">
<h2 class="anchored" data-anchor-id="train-function">Train function</h2>
<ul>
<li>for every epoch it first trains on train_loader and do a validation on val_loader</li>
<li>here we are using tqdm for a progress bar</li>
<li><strong>Default hyperparameters</strong></li>
<li>epochs per fold =: 3</li>
<li>learning rate =: 1e-4</li>
<li>loss function =: CrossEntropyLoss</li>
<li>optimizer =: AdamW with lr = 1e-4 and defaults betas (0.9,0.99) with 0.01 default weight decay</li>
</ul>
<p>superconvergence post[https://www.fast.ai/posts/2018-07-02-adam-weight-decay.html]</p>
<p><strong>there are some optimizations like:</strong> * deleting model at end and saving best weights * deleting images and labels sent to gpu at end * <strong>Half precision</strong> for validation , since we dont have to update weights here, using half precision makes it fast for fast evaluating.</p>
<div id="cell-13" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:30:27.390215Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:30:27.389856Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:30:27.408355Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:30:27.407429Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:30:27.390180Z&quot;}" data-trusted="true" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(train_loader, val_loader, model, epochs<span class="op">=</span><span class="dv">3</span>, lr<span class="op">=</span><span class="fl">1e-4</span>, model_name<span class="op">=</span><span class="st">"model"</span>,lossf <span class="op">=</span> nn.CrossEntropyLoss(),best_acc<span class="op">=</span><span class="fl">0.0</span>):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    model.to(device)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>    model.train()</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(os.path.exists(<span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">_model.pth"</span>)):</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>        model.load_state_dict(torch.load(<span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">_model.pth"</span>))  <span class="co">#saving best weights</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"weights of </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> loaded"</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    optim <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span>lr)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    losslist <span class="op">=</span> []</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    accuracylist <span class="op">=</span> []</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    y_true <span class="op">=</span> []</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    y_pred <span class="op">=</span> []</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Training loop</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>        total_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>        total_correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>        total_samples <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span class="co">#progress bar </span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>        train_progress <span class="op">=</span> tqdm(<span class="bu">enumerate</span>(train_loader), total<span class="op">=</span><span class="bu">len</span>(train_loader), desc<span class="op">=</span><span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss"> (Training) for </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch_idx, (imgs, labels) <span class="kw">in</span> train_progress:</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>            imgs, labels <span class="op">=</span> imgs.to(device), labels.to(device)</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>            out <span class="op">=</span> model(imgs)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> lossf(out, labels)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>            optim.zero_grad(set_to_none<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>            optim.step()</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>            total_loss <span class="op">+=</span> loss.item() </span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>            _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(out.data, <span class="dv">1</span>)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>            total_correct <span class="op">+=</span> (predicted <span class="op">==</span> labels).<span class="bu">sum</span>().item()</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>            total_samples <span class="op">+=</span> labels.size(<span class="dv">0</span>)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>            loss_now <span class="op">=</span> total_loss <span class="op">/</span> (batch_idx <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>            accuracy_now <span class="op">=</span> total_correct <span class="op">/</span> total_samples</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>            train_progress.set_postfix(loss<span class="op">=</span>loss_now, acc<span class="op">=</span>accuracy_now)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>            <span class="kw">del</span> imgs, labels</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Validation loop</span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>        total_val_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>        total_val_correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>        total_val_samples <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>        val_progress <span class="op">=</span> tqdm(<span class="bu">enumerate</span>(val_loader), total<span class="op">=</span><span class="bu">len</span>(val_loader), desc<span class="op">=</span><span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>epochs<span class="sc">}</span><span class="ss"> (Validation) for </span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>        <span class="co">#model.eval() to turn dropout off and stop tracking gradients</span></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch_idx, (imgs, labels) <span class="kw">in</span> val_progress:</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>                imgs, labels <span class="op">=</span> imgs.to(device), labels.to(device)</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>                <span class="cf">with</span> torch.autocast(device_type<span class="op">=</span><span class="st">"cuda"</span>):<span class="co">##Half preicision</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a>                    out <span class="op">=</span> model(imgs)</span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a>                    loss <span class="op">=</span> lossf(out, labels)</span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a>                total_val_loss <span class="op">+=</span> loss.item() </span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>                _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(out.data, <span class="dv">1</span>)</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>                total_val_correct <span class="op">+=</span> (predicted <span class="op">==</span> labels).<span class="bu">sum</span>().item()</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>                total_val_samples <span class="op">+=</span> labels.size(<span class="dv">0</span>)</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>                val_loss_now <span class="op">=</span> total_val_loss <span class="op">/</span> (batch_idx <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>                val_accuracy_now <span class="op">=</span> total_val_correct <span class="op">/</span> total_val_samples</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>                val_progress.set_postfix(loss<span class="op">=</span>val_loss_now, acc<span class="op">=</span>val_accuracy_now)</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>                y_true.extend(labels.cpu().numpy())</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a>                y_pred.extend(predicted.cpu().numpy())</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>                <span class="kw">del</span> imgs, labels</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a>        losslist.append(total_val_loss <span class="op">/</span> <span class="bu">len</span>(val_loader))</span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>        val_acc <span class="op">=</span> total_val_correct <span class="op">/</span> total_val_samples</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a>        accuracylist.append(val_acc)</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a>        <span class="co">#saving best model</span></span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> val_acc <span class="op">&gt;</span> best_acc:</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a>            best_acc <span class="op">=</span> val_acc</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a>            save(model, <span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss">_model.pth"</span>)</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>model_name<span class="sc">}</span><span class="ss"> weights saved with best accuracy :</span><span class="sc">{</span>best_acc<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a>                </span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a>    <span class="kw">del</span> model</span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Training completed weight saved."</span>)</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> losslist, accuracylist, y_true, y_pred, best_acc</span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> save(model, path):</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a>    torch.save(model.state_dict(), path)</span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Model saved to </span><span class="sc">{</span>path<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="main-one-vs-rest-binary-classification-function" class="level2">
<h2 class="anchored" data-anchor-id="main-one-vs-rest-binary-classification-function">Main One vs Rest binary classification function</h2>
<ul>
<li>Here we will select some class and then perform binary classification on it means, we assign 1 label to selected class and 0 label to other classes and then take loss by <strong>CrossEntropy</strong> and perform weights update.</li>
<li>for every data class we will make a train and Validation Dataloader for 3 folds and collect data like loss and accuracy to plot</li>
</ul>
</section>
<section id="dataloader" class="level2">
<h2 class="anchored" data-anchor-id="dataloader">Dataloader</h2>
<ul>
<li>taking images from a particular data index class and other data classes, and for binary classification we set data index class labels as 1 and other labels as 0</li>
<li>here take is a parameter which defines how much to take from other classes currently we take 10% of other classes and it works.</li>
<li>setting number of workers 2 and pin memory for faster data caching</li>
<li>SubsetRandomSampler for selecting indices</li>
</ul>
<p><strong>Batch Size</strong> * batch size is 32 * since GPU we are using P100 has enough memory and bottleneck is not gpu but cpu for data caching.</p>
<div id="cell-17" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:30:27.409808Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:30:27.409527Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:30:27.427532Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:30:27.426679Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:30:27.409785Z&quot;}" data-trusted="true" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> one_vs_rest(model,model_name, data_index, n_fold<span class="op">=</span><span class="dv">3</span>,batch_size<span class="op">=</span><span class="dv">32</span>, num_workers<span class="op">=</span><span class="dv">2</span>,img_path <span class="op">=</span> <span class="st">"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals"</span>,best_acc<span class="op">=</span><span class="fl">0.0</span>):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Data loading</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> []</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> []</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> folder <span class="kw">in</span> os.listdir(img_path):</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        anim_fold <span class="op">=</span> os.path.join(img_path, folder)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> folder <span class="op">==</span> os.listdir(img_path)[data_index]:</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>            take <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>            take <span class="op">=</span> <span class="fl">0.25</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        tot_len <span class="op">=</span> <span class="bu">len</span>(os.listdir(anim_fold))</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> t,img_file <span class="kw">in</span> <span class="bu">enumerate</span>(os.listdir(anim_fold)):</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> t<span class="op">&gt;=</span>take<span class="op">*</span>tot_len:</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>            img_path_full <span class="op">=</span> os.path.join(anim_fold, img_file)</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>            images.append(img_path_full)</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> folder <span class="op">==</span> os.listdir(img_path)[data_index]:</span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>                labels.append(<span class="dv">1</span>)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>                labels.append(<span class="dv">0</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> np.array(images)</span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> np.array(labels)</span>
<span id="cb6-23"><a href="#cb6-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-24"><a href="#cb6-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define dataset and indices</span></span>
<span id="cb6-25"><a href="#cb6-25" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> Data(images<span class="op">=</span>images, labels<span class="op">=</span>labels)</span>
<span id="cb6-26"><a href="#cb6-26" aria-hidden="true" tabindex="-1"></a>    kf <span class="op">=</span> KFold(n_splits<span class="op">=</span>n_fold, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">42</span>)<span class="co">##3 fold </span></span>
<span id="cb6-27"><a href="#cb6-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-28"><a href="#cb6-28" aria-hidden="true" tabindex="-1"></a>    allloss <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb6-29"><a href="#cb6-29" aria-hidden="true" tabindex="-1"></a>    allacc <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb6-30"><a href="#cb6-30" aria-hidden="true" tabindex="-1"></a>    ally_true <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb6-31"><a href="#cb6-31" aria-hidden="true" tabindex="-1"></a>    ally_pred <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb6-32"><a href="#cb6-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-33"><a href="#cb6-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-34"><a href="#cb6-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> fold, (train_indices, val_indices) <span class="kw">in</span> <span class="bu">enumerate</span>(kf.split(dataset)):</span>
<span id="cb6-35"><a href="#cb6-35" aria-hidden="true" tabindex="-1"></a>        train_sampler <span class="op">=</span> torch.utils.data.SubsetRandomSampler(train_indices)</span>
<span id="cb6-36"><a href="#cb6-36" aria-hidden="true" tabindex="-1"></a>        train_loader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span>batch_size, sampler<span class="op">=</span>train_sampler, num_workers<span class="op">=</span>num_workers, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-37"><a href="#cb6-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-38"><a href="#cb6-38" aria-hidden="true" tabindex="-1"></a>        val_sampler <span class="op">=</span> torch.utils.data.SubsetRandomSampler(val_indices)</span>
<span id="cb6-39"><a href="#cb6-39" aria-hidden="true" tabindex="-1"></a>        val_loader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span>batch_size, sampler<span class="op">=</span>val_sampler, num_workers<span class="op">=</span>num_workers, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-40"><a href="#cb6-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-41"><a href="#cb6-41" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Fold </span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:"</span>)  </span>
<span id="cb6-42"><a href="#cb6-42" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-43"><a href="#cb6-43" aria-hidden="true" tabindex="-1"></a>        losslist, acclist, y_true, y_pred, best_acc <span class="op">=</span> train(train_loader, val_loader, model,  model_name<span class="op">=</span>model_name, best_acc<span class="op">=</span>best_acc)</span>
<span id="cb6-44"><a href="#cb6-44" aria-hidden="true" tabindex="-1"></a>        allloss[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(losslist)</span>
<span id="cb6-45"><a href="#cb6-45" aria-hidden="true" tabindex="-1"></a>        allacc[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(acclist)</span>
<span id="cb6-46"><a href="#cb6-46" aria-hidden="true" tabindex="-1"></a>        ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(y_true)</span>
<span id="cb6-47"><a href="#cb6-47" aria-hidden="true" tabindex="-1"></a>        ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(y_pred)</span>
<span id="cb6-48"><a href="#cb6-48" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb6-49"><a href="#cb6-49" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> allloss,allacc,ally_true,ally_pred, best_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="custommodel" class="level2">
<h2 class="anchored" data-anchor-id="custommodel">CustomModel</h2>
<ul>
<li><strong>We used model with AttentionBlock to emphasize the importance of image patches.to focus on important part of images and discared irrelevant parts.although it is helpful in medical datasets but in animal datasets maybe there is a big landscape with animal in small pixels for eg with birds, there attention will be useful.</strong></li>
</ul>
</section>
<section id="components" class="level2">
<h2 class="anchored" data-anchor-id="components"><em>Components</em></h2>
</section>
<section id="convolution-blocks" class="level1">
<h1>Convolution Blocks</h1>
<ul>
<li>There are 5 Conv Blocks each constituting:</li>
<li>conv2d batchnorm relu conv2d batchnorm relu and maxpool at the end</li>
<li>these convblocks are commonly used.</li>
<li>batchnorm is used to stabilise training from covariate shift [https://arxiv.org/abs/1502.03167]</li>
<li>ReLU is used as an activation function as used by imagenet paper.</li>
</ul>
</section>
<section id="hyperparameters" class="level1">
<h1>Hyperparameters</h1>
<ul>
<li>kernel size : 3 for Conv filters and :=2 for MaxPooling</li>
</ul>
<section id="attention-block" class="level2">
<h2 class="anchored" data-anchor-id="attention-block">Attention Block</h2>
<ul>
<li>The intermediate features is the output of pool-3 or pool-4 and the global feature vector (output of pool-5) is fed as input to the attention layer.</li>
<li>feature upsampling is done via bilinear interpolation to mak intermediate and global feature vector same shape.</li>
<li>After that an element wise sum is done followed by a convolution operation that just reduces the 256 channels to 1.</li>
<li>This is then fed into a Softmax layer, which gives us a normalized Attention map (A). Each scalar element in A represents the degree of attention to the corresponding spatial feature vector in F.</li>
<li>The new feature vector  is then computed by pixel-wise multiplication. That is, each feature vector f is multiplied by the attention element a</li>
<li>So, the attention map A and the new feature vector  are the outputs of the Attention Layer.</li>
</ul>
<p>[https://github.com/SaoYan/IPMI2019-AttnMel/blob/99e4a9b71717fb51f24d7994948b6a0e76bb8d58/networks.py]</p>
</section>
<section id="initialising" class="level2">
<h2 class="anchored" data-anchor-id="initialising">Initialising</h2>
<ul>
<li><p>we initialise with kaiming normal to prevent gradient vanishing or exploding latter on.</p></li>
<li><p>Conv2d Layers: initializes the weights using the Kaiming normal.</p></li>
<li><p>BatchNorm2d Layers: it sets the weights to 1 and biases to 0.</p></li>
<li><p>Linear Layers: initializes the weights from a normal distribution with mean 0 and standard deviation 0.01. It sets the biases to 0.</p></li>
</ul>
<div id="cell-23" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:30:27.429188Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:30:27.428910Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:30:27.458272Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:30:27.457325Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:30:27.429164Z&quot;}" data-trusted="true" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AttentionBlock(nn.Module):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, in_features_l, in_features_g, attn_features, up_factor, normalize_attn<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(AttentionBlock, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.up_factor <span class="op">=</span> up_factor</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.normalize_attn <span class="op">=</span> normalize_attn</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W_l <span class="op">=</span> nn.Conv2d(in_channels<span class="op">=</span>in_features_l, out_channels<span class="op">=</span>attn_features, kernel_size<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">0</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.W_g <span class="op">=</span> nn.Conv2d(in_channels<span class="op">=</span>in_features_g, out_channels<span class="op">=</span>attn_features, kernel_size<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">0</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.phi <span class="op">=</span> nn.Conv2d(in_channels<span class="op">=</span>attn_features, out_channels<span class="op">=</span><span class="dv">1</span>, kernel_size<span class="op">=</span><span class="dv">1</span>, padding<span class="op">=</span><span class="dv">0</span>, bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, l, g):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        N, C, W, H <span class="op">=</span> l.size()</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        l_ <span class="op">=</span> <span class="va">self</span>.W_l(l)</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        g_ <span class="op">=</span> <span class="va">self</span>.W_g(g)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.up_factor <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>            g_ <span class="op">=</span> F.interpolate(g_, scale_factor<span class="op">=</span><span class="va">self</span>.up_factor, mode<span class="op">=</span><span class="st">'bilinear'</span>, align_corners<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        c <span class="op">=</span> <span class="va">self</span>.phi(F.relu(l_ <span class="op">+</span> g_)) <span class="co"># batch_sizex1xWxH</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># compute attn map</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.normalize_attn:</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>            a <span class="op">=</span> F.softmax(c.view(N,<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>), dim<span class="op">=</span><span class="dv">2</span>).view(N,<span class="dv">1</span>,W,H)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>            a <span class="op">=</span> torch.sigmoid(c)</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="co"># re-weight the local feature</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        f <span class="op">=</span> torch.mul(a.expand_as(l), l) <span class="co"># batch_sizexCxWxH</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.normalize_attn:</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> f.view(N,C,<span class="op">-</span><span class="dv">1</span>).<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">2</span>) <span class="co"># weighted sum</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>            output <span class="op">=</span> F.adaptive_avg_pool2d(f, (<span class="dv">1</span>,<span class="dv">1</span>)).view(N,C) <span class="co"># global average pooling</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> a, output</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Model(nn.Module):</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes, normalize_attn<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_block1 <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">3</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(<span class="dv">64</span>),</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">64</span>, <span class="dv">64</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(<span class="dv">64</span>),</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_block2 <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">64</span>, <span class="dv">128</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(<span class="dv">128</span>),</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">128</span>, <span class="dv">128</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(<span class="dv">128</span>),</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_block3 <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">128</span>, <span class="dv">256</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(<span class="dv">256</span>),</span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">256</span>, <span class="dv">256</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(<span class="dv">256</span>),</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">256</span>, <span class="dv">256</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(<span class="dv">256</span>),</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_block4 <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">256</span>, <span class="dv">512</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(<span class="dv">512</span>),</span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">512</span>, <span class="dv">512</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(<span class="dv">512</span>),</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">512</span>, <span class="dv">512</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(<span class="dv">512</span>),</span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv_block5 <span class="op">=</span> nn.Sequential(</span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">512</span>, <span class="dv">512</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(<span class="dv">512</span>),</span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">512</span>, <span class="dv">512</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(<span class="dv">512</span>),</span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">512</span>, <span class="dv">512</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm2d(<span class="dv">512</span>),</span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(inplace<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(kernel_size<span class="op">=</span><span class="dv">2</span>, stride<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool <span class="op">=</span> nn.AvgPool2d(<span class="dv">7</span>, stride<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a>     </span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.cls <span class="op">=</span> nn.Linear(in_features<span class="op">=</span><span class="dv">768</span>, out_features<span class="op">=</span>num_classes, bias<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a>       <span class="co"># initialize the attention blocks defined above</span></span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attn1 <span class="op">=</span> AttentionBlock(<span class="dv">256</span>, <span class="dv">512</span>, <span class="dv">256</span>, <span class="dv">4</span>, normalize_attn<span class="op">=</span>normalize_attn)</span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a>               </span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reset_parameters(<span class="va">self</span>.cls)</span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.reset_parameters(<span class="va">self</span>.attn1)</span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> reset_parameters(<span class="va">self</span>, module):</span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> m <span class="kw">in</span> module.modules():</span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">isinstance</span>(m, nn.Conv2d):</span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a>                nn.init.kaiming_normal_(m.weight, mode<span class="op">=</span><span class="st">'fan_in'</span>, nonlinearity<span class="op">=</span><span class="st">'relu'</span>)</span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> m.bias <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a>                    nn.init.constant_(m.bias, <span class="fl">0.</span>)</span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="bu">isinstance</span>(m, nn.BatchNorm2d):</span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a>                nn.init.constant_(m.weight, <span class="fl">1.</span>)</span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a>                nn.init.constant_(m.bias, <span class="fl">0.</span>)</span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> <span class="bu">isinstance</span>(m, nn.Linear):</span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a>                nn.init.normal_(m.weight, <span class="fl">0.</span>, <span class="fl">0.01</span>)</span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a>                nn.init.constant_(m.bias, <span class="fl">0.</span>)</span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a>        block1 <span class="op">=</span> <span class="va">self</span>.conv_block1(x)       <span class="co"># /2</span></span>
<span id="cb7-112"><a href="#cb7-112" aria-hidden="true" tabindex="-1"></a>        block2 <span class="op">=</span> <span class="va">self</span>.conv_block2(block1)  <span class="co"># /4</span></span>
<span id="cb7-113"><a href="#cb7-113" aria-hidden="true" tabindex="-1"></a>        block3 <span class="op">=</span> <span class="va">self</span>.conv_block3(block2)  <span class="co"># /8</span></span>
<span id="cb7-114"><a href="#cb7-114" aria-hidden="true" tabindex="-1"></a>        block4 <span class="op">=</span> <span class="va">self</span>.conv_block4(block3)  <span class="co"># /16</span></span>
<span id="cb7-115"><a href="#cb7-115" aria-hidden="true" tabindex="-1"></a>        block5 <span class="op">=</span> <span class="va">self</span>.conv_block5(block4)  <span class="co"># /32</span></span>
<span id="cb7-116"><a href="#cb7-116" aria-hidden="true" tabindex="-1"></a>        N, __, __, __ <span class="op">=</span> block5.size()</span>
<span id="cb7-117"><a href="#cb7-117" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb7-118"><a href="#cb7-118" aria-hidden="true" tabindex="-1"></a>        g <span class="op">=</span> <span class="va">self</span>.pool(block5).view(N,<span class="dv">512</span>)</span>
<span id="cb7-119"><a href="#cb7-119" aria-hidden="true" tabindex="-1"></a>        a1, g1 <span class="op">=</span> <span class="va">self</span>.attn1(block3, block5)</span>
<span id="cb7-120"><a href="#cb7-120" aria-hidden="true" tabindex="-1"></a>        g_hat <span class="op">=</span> torch.cat((g,g1), dim<span class="op">=</span><span class="dv">1</span>) <span class="co"># batch_size x C</span></span>
<span id="cb7-121"><a href="#cb7-121" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.cls(g_hat)</span>
<span id="cb7-122"><a href="#cb7-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-123"><a href="#cb7-123" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-24" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:30:27.459615Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:30:27.459331Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:30:29.585224Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:30:29.584121Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:30:27.459592Z&quot;}" data-trusted="true" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Model(<span class="dv">2</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.randn((<span class="dv">8</span>,<span class="dv">3</span>,<span class="dv">224</span>,<span class="dv">224</span>))</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>model(x)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>tensor([[ 0.1368, -0.0015],
        [ 0.1678, -0.0365],
        [ 0.1938,  0.0303],
        [ 0.1695, -0.0208],
        [ 0.1785,  0.0083],
        [ 0.1693, -0.0036],
        [ 0.1895, -0.0057],
        [ 0.1759,  0.0108]], grad_fn=&lt;AddmmBackward0&gt;)</code></pre>
</div>
</div>
</section>
<section id="now-we-just-for-every-data-class-perform-one-vs-rest-classification-for" class="level2">
<h2 class="anchored" data-anchor-id="now-we-just-for-every-data-class-perform-one-vs-rest-classification-for">Now we just for every data class perform One vs Rest classification for :</h2>
<ul>
<li><strong>Resnet</strong></li>
<li><strong>EfficientNet</strong></li>
<li><strong>CustomModel</strong></li>
</ul>
</section>
<section id="note-i-am-currently-performing-for-only-5-selected-class-due-to-compute-unavailability-and-kaggle-gpu-just-stucks-after-some-hours." class="level2">
<h2 class="anchored" data-anchor-id="note-i-am-currently-performing-for-only-5-selected-class-due-to-compute-unavailability-and-kaggle-gpu-just-stucks-after-some-hours.">|Note : i am currently performing for only 5 selected class, due to compute unavailability and kaggle GPU just stucks after some hours.</h2>
</section>
</section>
<section id="resnet" class="level1">
<h1>Resnet</h1>
<div id="cell-28" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:30:29.586833Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:30:29.586535Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:38:23.678391Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:38:23.677087Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:30:29.586808Z&quot;}" data-scrolled="true" data-trusted="true" data-execution_count="9">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>resnet <span class="op">=</span> torch.hub.load(<span class="st">'pytorch/vision:v0.10.0'</span>, <span class="st">'resnet18'</span>, pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>resnet.fc <span class="op">=</span> nn.Linear(<span class="dv">512</span>,<span class="dv">2</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>allloss <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>allacc <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>ally_true <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>ally_pred <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [allloss,allacc,ally_true,ally_pred]</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>timer <span class="op">=</span> []</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>best_acc_resnet <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>n_classes <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> data_idx <span class="kw">in</span> <span class="bu">range</span>(n_classes):</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> time.time()</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    loss,acc,y_true,y_pred,best_acc_resnet <span class="op">=</span> one_vs_rest(resnet,<span class="st">"Resnet_bi"</span>,data_idx,best_acc<span class="op">=</span>best_acc_resnet)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"-------------------data_class:</span><span class="sc">{</span>data_idx<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> completed---------------"</span>)</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"time elapsed:</span><span class="sc">{</span>time<span class="sc">.</span>time()<span class="op">-</span>s<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>    timer.append(time.time()<span class="op">-</span>s)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>    returned <span class="op">=</span> [loss,acc,y_true,y_pred]</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i,m <span class="kw">in</span> <span class="bu">enumerate</span>(metrics):</span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>            m[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(returned[i][<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0
/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.11it/s, acc=1, loss=0.00333]
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.47it/s, acc=1, loss=0.00301]
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.55it/s, acc=0.994, loss=0.0185]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.82it/s, acc=0.998, loss=0.01]  
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.53it/s, acc=0.998, loss=0.00718]
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.92it/s, acc=0.998, loss=0.00615]
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.45it/s, acc=0.999, loss=0.0059] 
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.25it/s, acc=0.998, loss=0.00262]
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.55it/s, acc=0.999, loss=0.00855]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.47it/s, acc=0.996, loss=0.00415]
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.54it/s, acc=0.996, loss=0.0968] 
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.37it/s, acc=0.998, loss=0.003]  
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.38it/s, acc=0.997, loss=0.0115] 
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.32it/s, acc=0.998, loss=0.0159]
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.31it/s, acc=0.997, loss=0.064]  
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.58it/s, acc=1, loss=0.00172]
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.64it/s, acc=1, loss=0.00705]
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.66it/s, acc=1, loss=0.00121]
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.25it/s, acc=0.958, loss=0.192]
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.79it/s, acc=0.981, loss=0.0378]
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.10it/s, acc=0.996, loss=0.0213]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.51it/s, acc=0.994, loss=0.0177]
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.39it/s, acc=0.998, loss=0.0121] 
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.41it/s, acc=0.994, loss=0.0176]
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.22it/s, acc=0.969, loss=0.119]
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.42it/s, acc=0.972, loss=0.0688]
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.27it/s, acc=0.994, loss=0.0231]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.06it/s, acc=0.978, loss=0.042] 
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.36it/s, acc=0.999, loss=0.00505]
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.56it/s, acc=0.985, loss=0.0463]
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.31it/s, acc=0.967, loss=0.121]
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.37it/s, acc=0.978, loss=0.0936]
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.44it/s, acc=0.999, loss=0.0126]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.17it/s, acc=0.983, loss=0.0588]
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.49it/s, acc=0.998, loss=0.0209] 
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.51it/s, acc=0.983, loss=0.0682]
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.11it/s, acc=0.966, loss=0.169]
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.84it/s, acc=0.97, loss=0.0921] 
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.30it/s, acc=0.994, loss=0.0244]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.50it/s, acc=0.983, loss=0.031] 
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.23it/s, acc=0.997, loss=0.00885]
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.73it/s, acc=0.989, loss=0.0269]
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.36it/s, acc=0.968, loss=0.128]
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.35it/s, acc=0.976, loss=0.0623]
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.44it/s, acc=0.999, loss=0.0127]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.14it/s, acc=0.976, loss=0.0467]
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.60it/s, acc=1, loss=0.00493]
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.30it/s, acc=0.978, loss=0.0405]
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.46it/s, acc=0.96, loss=0.147] 
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.22it/s, acc=0.989, loss=0.0302]
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.11it/s, acc=0.994, loss=0.0212]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.50it/s, acc=0.983, loss=0.0424]
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.55it/s, acc=0.997, loss=0.00762]
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.52it/s, acc=0.996, loss=0.0139]
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.13it/s, acc=0.965, loss=0.171]
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.28it/s, acc=0.959, loss=0.146]
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.22it/s, acc=0.989, loss=0.0291]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.42it/s, acc=0.987, loss=0.0367]
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.24it/s, acc=0.997, loss=0.0468] 
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.51it/s, acc=0.985, loss=0.0601]
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.15it/s, acc=0.966, loss=0.225]
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.30it/s, acc=0.968, loss=0.0986]
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.45it/s, acc=0.995, loss=0.0219]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.22it/s, acc=0.974, loss=0.0726]
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.35it/s, acc=0.999, loss=0.00951]
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.45it/s, acc=0.978, loss=0.0565]
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.42it/s, acc=0.959, loss=0.157]
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.23it/s, acc=0.978, loss=0.0482]
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.29it/s, acc=0.995, loss=0.0215]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  3.84it/s, acc=0.987, loss=0.0342]
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.41it/s, acc=0.999, loss=0.00732]
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.52it/s, acc=0.983, loss=0.0532]
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.30it/s, acc=0.963, loss=0.157]
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.48it/s, acc=0.991, loss=0.0217]
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.34it/s, acc=0.999, loss=0.0105]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.72it/s, acc=0.998, loss=0.00892]
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.36it/s, acc=0.999, loss=0.00607]
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.68it/s, acc=0.996, loss=0.0141]
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.15it/s, acc=0.975, loss=0.109]
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.47it/s, acc=0.985, loss=0.09]  
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.16it/s, acc=0.996, loss=0.0156]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.34it/s, acc=0.987, loss=0.0379]
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.67it/s, acc=0.999, loss=0.00446]
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.40it/s, acc=0.985, loss=0.0378]
Epoch 1/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.38it/s, acc=0.971, loss=0.114]
Epoch 1/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.09it/s, acc=0.998, loss=0.0158]
Epoch 2/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.33it/s, acc=0.999, loss=0.00982]
Epoch 2/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.10it/s, acc=0.998, loss=0.0113]
Epoch 3/3 (Training) for Resnet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.37it/s, acc=1, loss=0.0041] 
Epoch 3/3 (Validation) for Resnet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.53it/s, acc=0.996, loss=0.00746]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Fold 1:
weights of Resnet_bi loaded
Model saved to Resnet_bi_model.pth
Resnet_bi weights saved with best accuracy :1.0
Training completed weight saved.
Fold 2:
weights of Resnet_bi loaded
Training completed weight saved.
Fold 3:
weights of Resnet_bi loaded
Training completed weight saved.
-------------------data_class:1 completed---------------
time elapsed:92.78 seconds
Fold 1:
weights of Resnet_bi loaded
Training completed weight saved.
Fold 2:
weights of Resnet_bi loaded
Training completed weight saved.
Fold 3:
weights of Resnet_bi loaded
Training completed weight saved.
-------------------data_class:2 completed---------------
time elapsed:95.27 seconds
Fold 1:
weights of Resnet_bi loaded
Training completed weight saved.
Fold 2:
weights of Resnet_bi loaded
Training completed weight saved.
Fold 3:
weights of Resnet_bi loaded
Training completed weight saved.
-------------------data_class:3 completed---------------
time elapsed:94.57 seconds
Fold 1:
weights of Resnet_bi loaded
Training completed weight saved.
Fold 2:
weights of Resnet_bi loaded
Training completed weight saved.
Fold 3:
weights of Resnet_bi loaded
Training completed weight saved.
-------------------data_class:4 completed---------------
time elapsed:96.31 seconds
Fold 1:
weights of Resnet_bi loaded
Training completed weight saved.
Fold 2:
weights of Resnet_bi loaded
Training completed weight saved.
Fold 3:
weights of Resnet_bi loaded
Training completed weight saved.
-------------------data_class:5 completed---------------
time elapsed:94.90 seconds</code></pre>
</div>
</div>
<section id="since-90-classes-are-lot-we-will-plot-foldwise-mean-of-loss-accuracy-and-confusion-matrix-for-all-classes" class="level2">
<h2 class="anchored" data-anchor-id="since-90-classes-are-lot-we-will-plot-foldwise-mean-of-loss-accuracy-and-confusion-matrix-for-all-classes">Since 90 classes are lot, we will plot foldwise mean of loss accuracy and confusion matrix for <strong>all classes</strong></h2>
</section>
<section id="resnet-plots" class="level2">
<h2 class="anchored" data-anchor-id="resnet-plots">Resnet Plots</h2>
<div id="cell-30" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:38:23.683709Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:38:23.683340Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:38:25.778356Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:38:25.777218Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:38:23.683673Z&quot;}" data-trusted="true" data-execution_count="10">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_loss(allloss):</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>        axs[i].plot(np.mean(allloss[<span class="ss">f"fold</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>],axis<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>], label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> fold"</span>,c<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>        axs[i].set_title(<span class="ss">f'Fold </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Validation Mean Loss'</span>)  </span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>        axs[i].set_xlabel(<span class="st">'Epochs/fold'</span>)</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>        axs[i].set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>        axs[i].legend()</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()  </span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_acc(allacc):</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>        axs[i].plot(np.mean(allacc[<span class="ss">f"fold</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>],axis<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>], label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> fold"</span>,c<span class="op">=</span><span class="st">'orange'</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>        axs[i].set_title(<span class="ss">f'Fold </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Validation Mean Accuracy'</span>)  </span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>        axs[i].set_xlabel(<span class="st">'Epochs/fold'</span>)</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>        axs[i].set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>        axs[i].legend()</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()  </span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cm(all_y_true, all_y_pred):</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):    </span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>        real <span class="op">=</span> []</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])):</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>            real.extend(ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>][i][<span class="dv">0</span>])</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> []</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])):</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>            pred.extend(ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>][i][<span class="dv">0</span>])</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>        cm <span class="op">=</span> confusion_matrix(real, pred)</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>        ConfusionMatrixDisplay(cm).plot(ax<span class="op">=</span>axs[fold],cmap<span class="op">=</span><span class="st">'Blues'</span>,values_format<span class="op">=</span><span class="st">'d'</span>)</span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>        axs[fold].set_title(<span class="ss">f"Fold </span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>plot_loss(allloss)</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>plot_acc(allacc)</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>plot_cm(ally_true,ally_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-11-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-11-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="efficientnet-b0" class="level1">
<h1>EfficientNet b0</h1>
<div id="cell-32" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:38:25.780056Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:38:25.779774Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:46:44.590958Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:46:44.589874Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:38:25.780031Z&quot;}" data-scrolled="true" data-trusted="true" data-execution_count="11">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>efficientnet <span class="op">=</span> models.efficientnet_b0(pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>efficientnet.classifier[<span class="dv">1</span>] <span class="op">=</span> nn.Linear(<span class="dv">1280</span>,<span class="dv">2</span>)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>allloss <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>allacc <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>ally_true <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>ally_pred <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [allloss,allacc,ally_true,ally_pred]</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>timee <span class="op">=</span> []</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>best_acc_eff <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> data_idx <span class="kw">in</span> <span class="bu">range</span>(n_classes):</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> time.time()</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    loss,acc,y_true,y_pred,best_acc_eff <span class="op">=</span> one_vs_rest(efficientnet,<span class="st">"EfficientNet_bi"</span>,data_idx,best_acc<span class="op">=</span>best_acc_eff)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"-------------------data_class:</span><span class="sc">{</span>data_idx<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> completed---------------"</span>)</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"time elapsed:</span><span class="sc">{</span>time<span class="sc">.</span>time()<span class="op">-</span>s<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    timee.append(time.time()<span class="op">-</span>s)</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>    returned <span class="op">=</span> [loss,acc,y_true,y_pred]</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i,m <span class="kw">in</span> <span class="bu">enumerate</span>(metrics):</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>            m[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(returned[i][<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  3.77it/s, acc=0.997, loss=0.0832] 
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.42it/s, acc=1, loss=0.00237]
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.10it/s, acc=1, loss=0.00467]
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.71it/s, acc=1, loss=0.0047] 
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  3.91it/s, acc=1, loss=0.00315]
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.63it/s, acc=1, loss=0.00438]
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.13it/s, acc=1, loss=0.00203]
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.05it/s, acc=1, loss=0.00432]
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.08it/s, acc=1, loss=0.000977]
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.29it/s, acc=1, loss=0.00251]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.20it/s, acc=1, loss=0.000376]
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:04&lt;00:00,  3.71it/s, acc=1, loss=0.0013] 
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.32it/s, acc=0.999, loss=0.00685]
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.29it/s, acc=1, loss=0.00194]
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.12it/s, acc=1, loss=0.00153] 
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.53it/s, acc=1, loss=0.00184]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.21it/s, acc=1, loss=0.00127]
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:04&lt;00:00,  3.71it/s, acc=1, loss=0.00127]
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.01it/s, acc=0.946, loss=0.227]
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.43it/s, acc=0.991, loss=0.0465]
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.10it/s, acc=0.987, loss=0.0405]
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.41it/s, acc=0.994, loss=0.0244]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  3.83it/s, acc=0.997, loss=0.0192]
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.75it/s, acc=0.994, loss=0.0253]
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.25it/s, acc=0.963, loss=0.169]
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.00it/s, acc=0.966, loss=0.133]
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.34it/s, acc=0.988, loss=0.0406]
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.04it/s, acc=0.972, loss=0.0876]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.08it/s, acc=0.996, loss=0.0184]
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.17it/s, acc=0.978, loss=0.0637]
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.32it/s, acc=0.951, loss=0.208]
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.30it/s, acc=0.974, loss=0.101] 
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.19it/s, acc=0.989, loss=0.0406]
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.43it/s, acc=0.978, loss=0.0749]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  3.81it/s, acc=0.994, loss=0.0222]
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.21it/s, acc=0.981, loss=0.0593]
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.13it/s, acc=0.951, loss=0.179]
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.35it/s, acc=0.981, loss=0.0728]
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  3.94it/s, acc=0.988, loss=0.147] 
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.14it/s, acc=0.987, loss=0.0532]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.09it/s, acc=0.996, loss=0.0182]
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.27it/s, acc=0.987, loss=0.0468]
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.12it/s, acc=0.962, loss=0.148]
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  3.97it/s, acc=0.966, loss=0.123]
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.05it/s, acc=0.984, loss=0.0437]
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.00it/s, acc=0.974, loss=0.0792]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.33it/s, acc=0.996, loss=0.0196]
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.14it/s, acc=0.97, loss=0.069]  
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.11it/s, acc=0.953, loss=0.235]
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.19it/s, acc=0.966, loss=0.121]
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  3.99it/s, acc=0.984, loss=0.0658]
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.48it/s, acc=0.976, loss=0.0951]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.23it/s, acc=0.991, loss=0.0288]
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.20it/s, acc=0.981, loss=0.0597]
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.19it/s, acc=0.954, loss=0.17] 
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.11it/s, acc=0.978, loss=0.0813]
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  3.98it/s, acc=0.977, loss=0.152] 
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.38it/s, acc=0.985, loss=0.0493]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.08it/s, acc=0.997, loss=0.0218]
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.68it/s, acc=0.985, loss=0.0354]
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.21it/s, acc=0.96, loss=0.287] 
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.25it/s, acc=0.963, loss=0.118]
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.09it/s, acc=0.983, loss=0.0428]
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.19it/s, acc=0.968, loss=0.0869]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.23it/s, acc=0.99, loss=0.0278] 
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.03it/s, acc=0.981, loss=0.0688]
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.09it/s, acc=0.958, loss=0.187]
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.56it/s, acc=0.957, loss=0.152]
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  3.98it/s, acc=0.989, loss=0.0452]
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.25it/s, acc=0.976, loss=0.0743]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.21it/s, acc=0.99, loss=0.0237] 
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.25it/s, acc=0.978, loss=0.0533]
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  3.87it/s, acc=0.951, loss=0.18] 
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.31it/s, acc=0.981, loss=0.0538]
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.20it/s, acc=0.996, loss=0.0259]
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.56it/s, acc=0.991, loss=0.0264]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.08it/s, acc=0.997, loss=0.0145]
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.67it/s, acc=0.996, loss=0.0194]
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.16it/s, acc=0.972, loss=0.121]
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  3.92it/s, acc=0.972, loss=0.0906]
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:06&lt;00:00,  4.34it/s, acc=0.99, loss=0.0343] 
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.28it/s, acc=0.972, loss=0.0633]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.17it/s, acc=0.999, loss=0.00922]
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.15it/s, acc=0.974, loss=0.0559]
Epoch 1/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.15it/s, acc=0.959, loss=0.144]
Epoch 1/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  3.84it/s, acc=0.948, loss=0.11] 
Epoch 2/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.17it/s, acc=0.989, loss=0.0398]
Epoch 2/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.51it/s, acc=0.987, loss=0.0353]
Epoch 3/3 (Training) for EfficientNet_bi: 100%|| 30/30 [00:07&lt;00:00,  4.04it/s, acc=0.998, loss=0.0135]
Epoch 3/3 (Validation) for EfficientNet_bi: 100%|| 15/15 [00:03&lt;00:00,  4.53it/s, acc=0.991, loss=0.0277]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Fold 1:
weights of EfficientNet_bi loaded
Model saved to EfficientNet_bi_model.pth
EfficientNet_bi weights saved with best accuracy :1.0
Training completed weight saved.
Fold 2:
weights of EfficientNet_bi loaded
Training completed weight saved.
Fold 3:
weights of EfficientNet_bi loaded
Training completed weight saved.
-------------------data_class:1 completed---------------
time elapsed:100.31 seconds
Fold 1:
weights of EfficientNet_bi loaded
Training completed weight saved.
Fold 2:
weights of EfficientNet_bi loaded
Training completed weight saved.
Fold 3:
weights of EfficientNet_bi loaded
Training completed weight saved.
-------------------data_class:2 completed---------------
time elapsed:99.64 seconds
Fold 1:
weights of EfficientNet_bi loaded
Training completed weight saved.
Fold 2:
weights of EfficientNet_bi loaded
Training completed weight saved.
Fold 3:
weights of EfficientNet_bi loaded
Training completed weight saved.
-------------------data_class:3 completed---------------
time elapsed:100.25 seconds
Fold 1:
weights of EfficientNet_bi loaded
Training completed weight saved.
Fold 2:
weights of EfficientNet_bi loaded
Training completed weight saved.
Fold 3:
weights of EfficientNet_bi loaded
Training completed weight saved.
-------------------data_class:4 completed---------------
time elapsed:99.29 seconds
Fold 1:
weights of EfficientNet_bi loaded
Training completed weight saved.
Fold 2:
weights of EfficientNet_bi loaded
Training completed weight saved.
Fold 3:
weights of EfficientNet_bi loaded
Training completed weight saved.
-------------------data_class:5 completed---------------
time elapsed:99.12 seconds</code></pre>
</div>
</div>
</section>
<section id="efficientnet-plots" class="level1">
<h1>EfficientNet Plots</h1>
<div id="cell-34" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:46:44.593062Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:46:44.592760Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:46:46.631973Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:46:46.631028Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:46:44.593033Z&quot;}" data-trusted="true" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_loss(allloss):</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>        axs[i].plot(np.mean(allloss[<span class="ss">f"fold</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>],axis<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>], label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> fold"</span>,c<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>        axs[i].set_title(<span class="ss">f'Fold </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Validation Mean Loss'</span>)  </span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>        axs[i].set_xlabel(<span class="st">'Epochs/fold'</span>)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>        axs[i].set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>        axs[i].legend()</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()  </span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_acc(allacc):</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>        axs[i].plot(np.mean(allacc[<span class="ss">f"fold</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>],axis<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>], label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> fold"</span>,c<span class="op">=</span><span class="st">'orange'</span>)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        axs[i].set_title(<span class="ss">f'Fold </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Validation Mean Accuracy'</span>)  </span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        axs[i].set_xlabel(<span class="st">'Epochs/fold'</span>)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>        axs[i].set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>        axs[i].legend()</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()  </span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cm(all_y_true, all_y_pred):</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):    </span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>        real <span class="op">=</span> []</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])):</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>            real.extend(ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>][i][<span class="dv">0</span>])</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> []</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])):</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>            pred.extend(ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>][i][<span class="dv">0</span>])</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>        cm <span class="op">=</span> confusion_matrix(real, pred)</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>        ConfusionMatrixDisplay(cm).plot(ax<span class="op">=</span>axs[fold],cmap<span class="op">=</span><span class="st">'Blues'</span>,values_format<span class="op">=</span><span class="st">'d'</span>)</span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>        axs[fold].set_title(<span class="ss">f"Fold </span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>plot_loss(allloss)</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>plot_acc(allacc)</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>plot_cm(ally_true,ally_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-13-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-13-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-13-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="custommodel-1" class="level2">
<h2 class="anchored" data-anchor-id="custommodel-1">CustomModel</h2>
<p>::: {#cell-36 .cell _kg_hide-input=false execution={iopub.execute_input:2024-02-23T03:46:46.633452Z,iopub.status.busy:2024-02-23T03:46:46.633157Z,iopub.status.idle:2024-02-23T03:56:15.240233Z,shell.execute_reply:2024-02-23T03:56:15.239138Z,shell.execute_reply.started:2024-02-23T03:46:46.633427Z} scrolled=true trusted=true execution_count=13}</p>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>allloss <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>allacc <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>ally_true <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>ally_pred <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [allloss,allacc,ally_true,ally_pred]</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>timec <span class="op">=</span> []</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>best_acc_cust <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> data_idx <span class="kw">in</span> <span class="bu">range</span>(n_classes):</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> time.time()</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    loss,acc,y_true,y_pred,best_acc_cust <span class="op">=</span> one_vs_rest(model,<span class="st">"CustomAttModel_bi"</span>,data_idx,best_acc<span class="op">=</span>best_acc_cust)</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"-------------------data_class:</span><span class="sc">{</span>data_idx<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> completed---------------"</span>)</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"time elapsed:</span><span class="sc">{</span>time<span class="sc">.</span>time()<span class="op">-</span>s<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    timec.append(time.time()<span class="op">-</span>s)</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>    returned <span class="op">=</span> [loss,acc,y_true,y_pred]</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i,m <span class="kw">in</span> <span class="bu">enumerate</span>(metrics):</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>            m[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(returned[i][<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fold 1:
Model saved to CustomAttModel_bi_model.pth
CustomAttModel_bi weights saved with best accuracy :0.967741935483871
Training completed weight saved.
Fold 2:
weights of CustomAttModel_bi loaded
Training completed weight saved.
Fold 3:
weights of CustomAttModel_bi loaded
Training completed weight saved.
-------------------data_class:1 completed---------------
time elapsed:112.75 seconds
Fold 1:
weights of CustomAttModel_bi loaded
Training completed weight saved.
Fold 2:
weights of CustomAttModel_bi loaded
Training completed weight saved.
Fold 3:
weights of CustomAttModel_bi loaded
Training completed weight saved.
-------------------data_class:2 completed---------------
time elapsed:112.96 seconds
Fold 1:
weights of CustomAttModel_bi loaded
Training completed weight saved.
Fold 2:
weights of CustomAttModel_bi loaded
Training completed weight saved.
Fold 3:
weights of CustomAttModel_bi loaded
Model saved to CustomAttModel_bi_model.pth
CustomAttModel_bi weights saved with best accuracy :0.9720430107526882
Training completed weight saved.
-------------------data_class:3 completed---------------
time elapsed:113.43 seconds
Fold 1:
weights of CustomAttModel_bi loaded
Training completed weight saved.
Fold 2:
weights of CustomAttModel_bi loaded
Training completed weight saved.
Fold 3:
weights of CustomAttModel_bi loaded
Training completed weight saved.
-------------------data_class:4 completed---------------
time elapsed:116.66 seconds
Fold 1:
weights of CustomAttModel_bi loaded
Training completed weight saved.
Fold 2:
weights of CustomAttModel_bi loaded
Training completed weight saved.
Fold 3:
weights of CustomAttModel_bi loaded
Training completed weight saved.
-------------------data_class:5 completed---------------
time elapsed:112.79 seconds</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.36it/s, acc=0.945, loss=0.224]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.23it/s, acc=0.968, loss=0.148]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.42it/s, acc=0.949, loss=0.171]
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.38it/s, acc=0.88, loss=0.394] 
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.47it/s, acc=0.951, loss=0.173]
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.11it/s, acc=0.927, loss=0.249]
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.52it/s, acc=0.961, loss=0.219]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.08it/s, acc=0.942, loss=0.221]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.49it/s, acc=0.96, loss=0.168] 
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.25it/s, acc=0.953, loss=0.187]
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.40it/s, acc=0.961, loss=0.131]
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  3.97it/s, acc=0.951, loss=0.197]
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.54it/s, acc=0.958, loss=0.175]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.22it/s, acc=0.953, loss=0.212]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.55it/s, acc=0.959, loss=0.158]
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.00it/s, acc=0.953, loss=0.189]
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.50it/s, acc=0.959, loss=0.147]
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  3.95it/s, acc=0.951, loss=0.196]
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.43it/s, acc=0.948, loss=0.218]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.35it/s, acc=0.948, loss=0.166]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.48it/s, acc=0.948, loss=0.147]
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.39it/s, acc=0.908, loss=0.324]
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.47it/s, acc=0.951, loss=0.127]
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  3.85it/s, acc=0.966, loss=0.12] 
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.62it/s, acc=0.962, loss=0.156]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  3.76it/s, acc=0.933, loss=0.173]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.51it/s, acc=0.959, loss=0.136]
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:04&lt;00:00,  3.67it/s, acc=0.933, loss=0.178]
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.53it/s, acc=0.961, loss=0.123]
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  3.93it/s, acc=0.935, loss=0.216]
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.51it/s, acc=0.951, loss=0.159]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  3.94it/s, acc=0.578, loss=1.13]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.52it/s, acc=0.951, loss=0.131]
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.12it/s, acc=0.961, loss=0.144]
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.52it/s, acc=0.963, loss=0.117]
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  3.98it/s, acc=0.959, loss=0.125]
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.42it/s, acc=0.958, loss=0.168]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.12it/s, acc=0.953, loss=0.228]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.46it/s, acc=0.959, loss=0.164]
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.27it/s, acc=0.953, loss=0.209]
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.36it/s, acc=0.956, loss=0.141]
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.17it/s, acc=0.953, loss=0.149]
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.59it/s, acc=0.962, loss=0.153]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.15it/s, acc=0.946, loss=0.241]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.52it/s, acc=0.962, loss=0.142]
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  3.83it/s, acc=0.946, loss=0.183]
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.51it/s, acc=0.962, loss=0.127]
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  3.86it/s, acc=0.933, loss=0.183]
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.55it/s, acc=0.949, loss=0.187]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.18it/s, acc=0.972, loss=0.132]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.35it/s, acc=0.949, loss=0.173]
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.13it/s, acc=0.972, loss=0.106] 
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.41it/s, acc=0.949, loss=0.154]
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.02it/s, acc=0.972, loss=0.126]
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.44it/s, acc=0.957, loss=0.158]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  3.81it/s, acc=0.957, loss=0.147]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:09&lt;00:00,  3.27it/s, acc=0.957, loss=0.142]
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.37it/s, acc=0.957, loss=0.15] 
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.40it/s, acc=0.957, loss=0.204]
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.11it/s, acc=0.957, loss=0.153]
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.37it/s, acc=0.963, loss=0.148]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:04&lt;00:00,  3.57it/s, acc=0.944, loss=0.174]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.38it/s, acc=0.963, loss=0.132]
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  3.92it/s, acc=0.944, loss=0.222]
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.35it/s, acc=0.963, loss=0.132]
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:04&lt;00:00,  3.61it/s, acc=0.944, loss=0.174]
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.51it/s, acc=0.949, loss=0.188]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:04&lt;00:00,  3.66it/s, acc=0.97, loss=0.143] 
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.35it/s, acc=0.951, loss=0.163]
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.20it/s, acc=0.948, loss=0.149]
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.41it/s, acc=0.952, loss=0.169]
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.05it/s, acc=0.97, loss=0.116] 
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.34it/s, acc=0.955, loss=0.172]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.31it/s, acc=0.942, loss=0.159]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.49it/s, acc=0.955, loss=0.19] 
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.16it/s, acc=0.946, loss=0.162]
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.52it/s, acc=0.947, loss=0.185]
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.38it/s, acc=0.963, loss=0.11] 
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.46it/s, acc=0.967, loss=0.14] 
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  3.99it/s, acc=0.869, loss=0.465]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.53it/s, acc=0.963, loss=0.125] 
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.07it/s, acc=0.942, loss=0.247]
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.51it/s, acc=0.965, loss=0.106] 
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.10it/s, acc=0.953, loss=0.143]
Epoch 1/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.56it/s, acc=0.951, loss=0.185]
Epoch 1/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:04&lt;00:00,  3.52it/s, acc=0.946, loss=0.198]
Epoch 2/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.54it/s, acc=0.944, loss=0.168]
Epoch 2/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:04&lt;00:00,  3.68it/s, acc=0.957, loss=0.136]
Epoch 3/3 (Training) for CustomAttModel_bi: 100%|| 30/30 [00:08&lt;00:00,  3.55it/s, acc=0.956, loss=0.12] 
Epoch 3/3 (Validation) for CustomAttModel_bi: 100%|| 15/15 [00:03&lt;00:00,  4.24it/s, acc=0.97, loss=0.0866] </code></pre>
</div>
<p>:::</p>
</section>
</section>
<section id="custommodel-plots" class="level1">
<h1>CustomModel Plots</h1>
<div id="cell-38" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:56:15.242203Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:56:15.241886Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:56:17.304453Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:56:17.303570Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:56:15.242173Z&quot;}" data-trusted="true" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_loss(allloss):</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>        axs[i].plot(np.mean(allloss[<span class="ss">f"fold</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>],axis<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>], label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> fold"</span>,c<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>        axs[i].set_title(<span class="ss">f'Fold </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Validation Mean Loss'</span>)  </span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>        axs[i].set_xlabel(<span class="st">'Epochs/fold'</span>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>        axs[i].set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>        axs[i].legend()</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()  </span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_acc(allacc):</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>        axs[i].plot(np.mean(allacc[<span class="ss">f"fold</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>],axis<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>], label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> fold"</span>,c<span class="op">=</span><span class="st">'orange'</span>)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>        axs[i].set_title(<span class="ss">f'Fold </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Validation Mean Accuracy'</span>)  </span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>        axs[i].set_xlabel(<span class="st">'Epochs/fold'</span>)</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>        axs[i].set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>        axs[i].legend()</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()  </span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cm(all_y_true, all_y_pred):</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):    </span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>        real <span class="op">=</span> []</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])):</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>            real.extend(ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>][i][<span class="dv">0</span>])</span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> []</span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])):</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>            pred.extend(ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>][i][<span class="dv">0</span>])</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>        cm <span class="op">=</span> confusion_matrix(real, pred)</span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>        ConfusionMatrixDisplay(cm).plot(ax<span class="op">=</span>axs[fold],cmap<span class="op">=</span><span class="st">'Blues'</span>,values_format<span class="op">=</span><span class="st">'d'</span>)</span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>        axs[fold].set_title(<span class="ss">f"Fold </span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a>plot_loss(allloss)</span>
<span id="cb21-42"><a href="#cb21-42" aria-hidden="true" tabindex="-1"></a>plot_acc(allacc)</span>
<span id="cb21-43"><a href="#cb21-43" aria-hidden="true" tabindex="-1"></a>plot_cm(ally_true,ally_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-15-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-15-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-15-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="comparing-best-accuracy-on-validation" class="level2">
<h2 class="anchored" data-anchor-id="comparing-best-accuracy-on-validation">Comparing Best Accuracy on Validation</h2>
<div id="cell-40" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:56:17.306493Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:56:17.305856Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:56:17.504561Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:56:17.503610Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:56:17.306456Z&quot;}" data-trusted="true" data-execution_count="15">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> [<span class="st">"resnet"</span>, <span class="st">"efficientnet"</span>, <span class="st">"custom"</span>]</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>accuracies <span class="op">=</span> [best_acc_resnet, best_acc_eff, best_acc_cust]</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a colormap</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">"orange"</span>,<span class="st">"blue"</span>,<span class="st">"red"</span>]</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> plt.bar(models, accuracies, color<span class="op">=</span>colors)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Models'</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Accuracy Comparison of Different Models'</span>)</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Adding the accuracy values on top of the bars</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bar, accuracy <span class="kw">in</span> <span class="bu">zip</span>(bars, accuracies):</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>    plt.text(bar.get_x() <span class="op">+</span> bar.get_width() <span class="op">/</span> <span class="dv">2</span>, bar.get_height() <span class="op">+</span> <span class="fl">0.005</span>, <span class="ss">f'</span><span class="sc">{</span>accuracy<span class="sc">:.2f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-16-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="time-taken" class="level1">
<h1>Time Taken</h1>
<div id="cell-42" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:56:17.505959Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:56:17.505684Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:56:17.917248Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:56:17.916364Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:56:17.505937Z&quot;}" data-trusted="true" data-execution_count="16">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> [<span class="st">"resnet"</span>, <span class="st">"efficientnet"</span>, <span class="st">"custom"</span>]</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>time <span class="op">=</span> [np.<span class="bu">sum</span>(timer), np.<span class="bu">sum</span>(timee), np.<span class="bu">sum</span>(timec)]</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a colormap</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">"orange"</span>,<span class="st">"blue"</span>,<span class="st">"red"</span>]</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> plt.bar(models, time, color<span class="op">=</span>colors)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Models'</span>)</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Time in Seconds'</span>)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Time taken for Different Models'</span>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bar, time <span class="kw">in</span> <span class="bu">zip</span>(bars, time):</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    plt.text(bar.get_x() <span class="op">+</span> bar.get_width() <span class="op">/</span> <span class="dv">2</span>, bar.get_height() <span class="op">+</span> <span class="fl">0.005</span>, <span class="ss">f'</span><span class="sc">{</span>time<span class="sc">:.2f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-17-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="five-class-classification" class="level1">
<h1>Five class classification</h1>
</section>
<section id="in-here-we-have-taken-5---5-classes-means-16-parts-of-90-class-dataset-each-containing-5-classes-and-perfomed-classification." class="level1">
<h1>in here, we have taken 5 - 5 classes, means 16 parts of 90 class dataset each containing 5 classes and perfomed classification.</h1>
</section>
<section id="for-example-take-classes-05-then-perform-classification-then-510-etc." class="level1">
<h1>for example take classes [0,5) then perform classification then [5,10) etc.</h1>
<div id="cell-45" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:56:17.918788Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:56:17.918503Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T03:56:17.932109Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T03:56:17.931128Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:56:17.918763Z&quot;}" data-trusted="true" data-execution_count="17">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> five_class_classify(model,model_name, data_index, n_fold<span class="op">=</span><span class="dv">3</span>,batch_size<span class="op">=</span><span class="dv">32</span>, num_workers<span class="op">=</span><span class="dv">2</span>,img_path <span class="op">=</span> <span class="st">"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals"</span>,best_acc<span class="op">=</span><span class="fl">0.0</span>):</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Data loading</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> []</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> []</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> offset,folder <span class="kw">in</span> <span class="bu">enumerate</span>(os.listdir(img_path)[data_index<span class="op">*</span><span class="dv">5</span>:data_index<span class="op">*</span><span class="dv">5</span><span class="op">+</span><span class="dv">5</span>]):</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        anim_fold <span class="op">=</span> os.path.join(img_path, folder)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> img_file <span class="kw">in</span> os.listdir(anim_fold):</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>            img_path_full <span class="op">=</span> os.path.join(anim_fold, img_file)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>            images.append(img_path_full)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>            labels.append(offset)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    images <span class="op">=</span> np.array(images)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    labels <span class="op">=</span> np.array(labels)</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Define dataset and indices</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> Data(images<span class="op">=</span>images, labels<span class="op">=</span>labels)</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>    kf <span class="op">=</span> KFold(n_splits<span class="op">=</span>n_fold, shuffle<span class="op">=</span><span class="va">True</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    allloss <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    allacc <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    ally_true <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    ally_pred <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> fold, (train_indices, val_indices) <span class="kw">in</span> <span class="bu">enumerate</span>(kf.split(dataset)):</span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>        train_sampler <span class="op">=</span> torch.utils.data.SubsetRandomSampler(train_indices)</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a>        train_loader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span>batch_size, sampler<span class="op">=</span>train_sampler, num_workers<span class="op">=</span>num_workers, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a>        val_sampler <span class="op">=</span> torch.utils.data.SubsetRandomSampler(val_indices)</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a>        val_loader <span class="op">=</span> DataLoader(dataset, batch_size<span class="op">=</span>batch_size, sampler<span class="op">=</span>val_sampler, num_workers<span class="op">=</span>num_workers, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Fold </span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">:"</span>)  </span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>        losslist, acclist, y_true, y_pred, best_acc <span class="op">=</span> train(train_loader, val_loader, model,  model_name<span class="op">=</span>model_name, best_acc<span class="op">=</span>best_acc)</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>        allloss[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(losslist)</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>        allacc[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(acclist)</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>        ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(y_true)</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>        ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(y_pred)</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> allloss,allacc,ally_true,ally_pred, best_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="resnet-1" class="level1">
<h1>Resnet</h1>
<div id="cell-47" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T03:56:17.934100Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T03:56:17.933371Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:04:23.612941Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:04:23.611820Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T03:56:17.934073Z&quot;}" data-scrolled="true" data-trusted="true" data-execution_count="18">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>resnet <span class="op">=</span> torch.hub.load(<span class="st">'pytorch/vision:v0.10.0'</span>, <span class="st">'resnet18'</span>, pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>resnet.fc <span class="op">=</span> nn.Linear(<span class="dv">512</span>,<span class="dv">5</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>allloss <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>allacc <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>ally_true <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>ally_pred <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [allloss,allacc,ally_true,ally_pred]</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>timer <span class="op">=</span> []</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>best_acc_resnet <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>n_classes <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> data_idx <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">5</span>):</span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> time.time()</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>    loss,acc,y_true,y_pred,best_acc_resnet <span class="op">=</span> one_vs_rest(resnet,<span class="st">"Resnet_five"</span>,data_idx,best_acc<span class="op">=</span>best_acc_resnet)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"-------------------data_class:</span><span class="sc">{</span>data_idx<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> completed---------------"</span>)</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"time elapsed:</span><span class="sc">{</span>time<span class="sc">.</span>time()<span class="op">-</span>s<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>    timer.append(time.time()<span class="op">-</span>s)</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>    returned <span class="op">=</span> [loss,acc,y_true,y_pred]</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i,m <span class="kw">in</span> <span class="bu">enumerate</span>(metrics):</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>            m[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(returned[i][<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0
/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.17it/s, acc=0.676, loss=1.02]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.65it/s, acc=0.987, loss=0.284]
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.26it/s, acc=0.991, loss=0.139]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.29it/s, acc=0.972, loss=0.133]
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.35it/s, acc=0.997, loss=0.0572]
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.52it/s, acc=0.994, loss=0.0558]
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.50it/s, acc=0.987, loss=0.0576]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.37it/s, acc=0.998, loss=0.0255]
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.47it/s, acc=0.995, loss=0.0224]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.49it/s, acc=0.994, loss=0.0196]
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.50it/s, acc=0.999, loss=0.00869]
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.20it/s, acc=0.996, loss=0.00767]
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.23it/s, acc=0.984, loss=0.0469]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.13it/s, acc=1, loss=0.00628]
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.48it/s, acc=0.998, loss=0.00928]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.17it/s, acc=1, loss=0.00316]
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.32it/s, acc=1, loss=0.00331]
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.14it/s, acc=1, loss=0.00172]
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.12it/s, acc=0.955, loss=0.161]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.55it/s, acc=0.985, loss=0.0345]
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.31it/s, acc=0.992, loss=0.0304]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.37it/s, acc=0.994, loss=0.0247]
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.00it/s, acc=0.996, loss=0.0155]
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.29it/s, acc=0.998, loss=0.013] 
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.30it/s, acc=0.969, loss=0.125]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.33it/s, acc=0.968, loss=0.0762]
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.58it/s, acc=0.996, loss=0.0168]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.14it/s, acc=0.983, loss=0.0483]
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.18it/s, acc=1, loss=0.00587]
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:04&lt;00:00,  3.70it/s, acc=0.987, loss=0.0383]
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.30it/s, acc=0.967, loss=0.136]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.17it/s, acc=0.978, loss=0.0658]
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.24it/s, acc=0.995, loss=0.0176]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.34it/s, acc=0.983, loss=0.0629]
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.18it/s, acc=0.998, loss=0.091]  
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.31it/s, acc=0.987, loss=0.0554]
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.25it/s, acc=0.953, loss=0.148]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.72it/s, acc=0.963, loss=0.112] 
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.02it/s, acc=0.992, loss=0.0242]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.52it/s, acc=0.991, loss=0.0332]
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.14it/s, acc=1, loss=0.00689]
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.49it/s, acc=0.989, loss=0.0269]
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.37it/s, acc=0.974, loss=0.108]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.31it/s, acc=0.983, loss=0.0416]
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.47it/s, acc=0.998, loss=0.0158]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  3.95it/s, acc=0.983, loss=0.0446]
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.25it/s, acc=0.999, loss=0.00751]
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.32it/s, acc=0.989, loss=0.0333]
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.44it/s, acc=0.965, loss=0.111]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.36it/s, acc=0.989, loss=0.0378]
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.19it/s, acc=0.996, loss=0.0217]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.45it/s, acc=0.987, loss=0.0289]
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.29it/s, acc=0.998, loss=0.00976]
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.25it/s, acc=0.996, loss=0.0136]
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.15it/s, acc=0.96, loss=0.129] 
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.35it/s, acc=0.97, loss=0.0838] 
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.19it/s, acc=0.995, loss=0.0213]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.43it/s, acc=0.978, loss=0.0658]
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.22it/s, acc=0.997, loss=0.0136]
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.37it/s, acc=0.985, loss=0.0425]
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.17it/s, acc=0.972, loss=0.0995]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.38it/s, acc=0.972, loss=0.0682]
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.36it/s, acc=0.995, loss=0.0235]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.23it/s, acc=0.985, loss=0.0585]
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.25it/s, acc=0.995, loss=0.0614]
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.26it/s, acc=0.985, loss=0.0527]
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.27it/s, acc=0.961, loss=0.123]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.42it/s, acc=0.987, loss=0.0424]
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.23it/s, acc=0.994, loss=0.0237]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.51it/s, acc=0.989, loss=0.033] 
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  3.96it/s, acc=0.999, loss=0.0102]
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.55it/s, acc=0.978, loss=0.0592]
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.27it/s, acc=0.97, loss=0.0971]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.56it/s, acc=0.994, loss=0.0207]
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.19it/s, acc=0.999, loss=0.0122]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.22it/s, acc=0.991, loss=0.016] 
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.13it/s, acc=1, loss=0.00436]
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.57it/s, acc=0.994, loss=0.0148]
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.33it/s, acc=0.975, loss=0.0846]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.18it/s, acc=0.983, loss=0.0542]
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.34it/s, acc=0.998, loss=0.0105]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  3.98it/s, acc=0.981, loss=0.0365]
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.33it/s, acc=1, loss=0.00367]
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.21it/s, acc=0.989, loss=0.0585]
Epoch 1/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.13it/s, acc=0.969, loss=0.107]
Epoch 1/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.16it/s, acc=0.994, loss=0.021] 
Epoch 2/3 (Training) for Resnet_five: 100%|| 30/30 [00:06&lt;00:00,  4.39it/s, acc=0.998, loss=0.0112]
Epoch 2/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  3.79it/s, acc=0.996, loss=0.016] 
Epoch 3/3 (Training) for Resnet_five: 100%|| 30/30 [00:07&lt;00:00,  4.19it/s, acc=0.998, loss=0.0375] 
Epoch 3/3 (Validation) for Resnet_five: 100%|| 15/15 [00:03&lt;00:00,  4.09it/s, acc=0.998, loss=0.0104] </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Fold 1:
Model saved to Resnet_five_model.pth
Resnet_five weights saved with best accuracy :0.9870967741935484
Model saved to Resnet_five_model.pth
Resnet_five weights saved with best accuracy :0.9935483870967742
Training completed weight saved.
Fold 2:
weights of Resnet_five loaded
Model saved to Resnet_five_model.pth
Resnet_five weights saved with best accuracy :0.9978494623655914
Training completed weight saved.
Fold 3:
weights of Resnet_five loaded
Model saved to Resnet_five_model.pth
Resnet_five weights saved with best accuracy :1.0
Training completed weight saved.
-------------------data_class:1 completed---------------
time elapsed:95.80 seconds
Fold 1:
weights of Resnet_five loaded
Training completed weight saved.
Fold 2:
weights of Resnet_five loaded
Training completed weight saved.
Fold 3:
weights of Resnet_five loaded
Training completed weight saved.
-------------------data_class:2 completed---------------
time elapsed:97.81 seconds
Fold 1:
weights of Resnet_five loaded
Training completed weight saved.
Fold 2:
weights of Resnet_five loaded
Training completed weight saved.
Fold 3:
weights of Resnet_five loaded
Training completed weight saved.
-------------------data_class:3 completed---------------
time elapsed:96.47 seconds
Fold 1:
weights of Resnet_five loaded
Training completed weight saved.
Fold 2:
weights of Resnet_five loaded
Training completed weight saved.
Fold 3:
weights of Resnet_five loaded
Training completed weight saved.
-------------------data_class:4 completed---------------
time elapsed:97.30 seconds
Fold 1:
weights of Resnet_five loaded
Training completed weight saved.
Fold 2:
weights of Resnet_five loaded
Training completed weight saved.
Fold 3:
weights of Resnet_five loaded
Training completed weight saved.
-------------------data_class:5 completed---------------
time elapsed:98.03 seconds</code></pre>
</div>
</div>
</section>
<section id="resnet-plots-1" class="level1">
<h1>Resnet Plots</h1>
<div id="cell-49" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T04:04:23.615270Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T04:04:23.614871Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:04:25.651962Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:04:25.650810Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T04:04:23.615230Z&quot;}" data-trusted="true" data-execution_count="19">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_loss(allloss):</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>        axs[i].plot(np.mean(allloss[<span class="ss">f"fold</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>],axis<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>], label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> fold"</span>,c<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>        axs[i].set_title(<span class="ss">f'Fold </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Validation Mean Loss'</span>)  </span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>        axs[i].set_xlabel(<span class="st">'Epochs/fold'</span>)</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>        axs[i].set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>        axs[i].legend()</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()  </span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_acc(allacc):</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>        axs[i].plot(np.mean(allacc[<span class="ss">f"fold</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>],axis<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>], label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> fold"</span>,c<span class="op">=</span><span class="st">'orange'</span>)</span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>        axs[i].set_title(<span class="ss">f'Fold </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Validation Mean Accuracy'</span>)  </span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>        axs[i].set_xlabel(<span class="st">'Epochs/fold'</span>)</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>        axs[i].set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>        axs[i].legend()</span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()  </span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cm(all_y_true, all_y_pred):</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):    </span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>        real <span class="op">=</span> []</span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])):</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>            real.extend(ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>][i][<span class="dv">0</span>])</span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> []</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])):</span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a>            pred.extend(ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>][i][<span class="dv">0</span>])</span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a>        cm <span class="op">=</span> confusion_matrix(real, pred)</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a>        ConfusionMatrixDisplay(cm).plot(ax<span class="op">=</span>axs[fold],cmap<span class="op">=</span><span class="st">'Blues'</span>,values_format<span class="op">=</span><span class="st">'d'</span>)</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>        axs[fold].set_title(<span class="ss">f"Fold </span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>plot_loss(allloss)</span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a>plot_acc(allacc)</span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>plot_cm(ally_true,ally_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-20-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-20-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-20-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="efficientnet" class="level1">
<h1>EfficientNet</h1>
<div id="cell-51" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T04:04:25.653309Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T04:04:25.653014Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:12:52.854273Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:12:52.853153Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T04:04:25.653283Z&quot;}" data-scrolled="true" data-trusted="true" data-execution_count="20">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>efficientnet <span class="op">=</span> torchvision.models.efficientnet_b0(pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>efficientnet.classifier[<span class="dv">1</span>] <span class="op">=</span> nn.Linear(<span class="dv">1280</span>,<span class="dv">5</span>)</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>allloss <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>allacc <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>ally_true <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>ally_pred <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [allloss,allacc,ally_true,ally_pred]</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>timee <span class="op">=</span> []</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>best_acc_eff <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> data_idx <span class="kw">in</span> <span class="bu">range</span>(n_classes):</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> time.time()</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>    loss,acc,y_true,y_pred,best_acc_eff <span class="op">=</span> one_vs_rest(efficientnet,<span class="st">"EfficientNet_five"</span>,data_idx,best_acc<span class="op">=</span>best_acc_eff)</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"-------------------data_class:</span><span class="sc">{</span>data_idx<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> completed---------------"</span>)</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"time elapsed:</span><span class="sc">{</span>time<span class="sc">.</span>time()<span class="op">-</span>s<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>    timee.append(time.time()<span class="op">-</span>s)</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>    returned <span class="op">=</span> [loss,acc,y_true,y_pred]</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i,m <span class="kw">in</span> <span class="bu">enumerate</span>(metrics):</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>            m[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(returned[i][<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.96it/s, acc=0.785, loss=1.06]
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.51it/s, acc=0.929, loss=0.654]
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.86it/s, acc=0.975, loss=0.363]
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.72it/s, acc=0.981, loss=0.244]
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.20it/s, acc=0.991, loss=0.131]
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.50it/s, acc=0.985, loss=0.153]
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.94it/s, acc=0.989, loss=0.069] 
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.34it/s, acc=1, loss=0.0348]
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.01it/s, acc=0.998, loss=0.0209]
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.16it/s, acc=0.996, loss=0.029] 
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.07it/s, acc=0.997, loss=0.0154]
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.06it/s, acc=0.996, loss=0.0225]
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.09it/s, acc=0.992, loss=0.0274]
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.39it/s, acc=1, loss=0.0138]
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.98it/s, acc=0.998, loss=0.0129]
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.05it/s, acc=1, loss=0.0116]
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.09it/s, acc=1, loss=0.00675]
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.29it/s, acc=0.996, loss=0.0155]
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.88it/s, acc=0.945, loss=0.265]
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  3.91it/s, acc=0.972, loss=0.0841]
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.76it/s, acc=0.984, loss=0.0757]
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.20it/s, acc=0.991, loss=0.063] 
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.84it/s, acc=0.99, loss=0.122]  
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.55it/s, acc=0.991, loss=0.0435]
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.02it/s, acc=0.955, loss=0.153]
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.23it/s, acc=0.953, loss=0.147]
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.12it/s, acc=0.991, loss=0.0554]
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.37it/s, acc=0.97, loss=0.0913] 
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:06&lt;00:00,  4.31it/s, acc=0.999, loss=0.0252]
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.47it/s, acc=0.983, loss=0.0729]
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.89it/s, acc=0.951, loss=0.25] 
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.20it/s, acc=0.957, loss=0.131]
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.19it/s, acc=0.987, loss=0.0733]
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.34it/s, acc=0.976, loss=0.0948]
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.99it/s, acc=0.995, loss=0.0373]
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.49it/s, acc=0.978, loss=0.0794]
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.85it/s, acc=0.949, loss=0.188]
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.60it/s, acc=0.974, loss=0.105]
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.00it/s, acc=0.985, loss=0.0605]
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.61it/s, acc=0.978, loss=0.0765]
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.05it/s, acc=0.996, loss=0.0325]
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.24it/s, acc=0.987, loss=0.0515]
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.15it/s, acc=0.96, loss=0.152] 
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  3.80it/s, acc=0.97, loss=0.155] 
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.25it/s, acc=0.986, loss=0.0549]
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.18it/s, acc=0.981, loss=0.0789]
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.18it/s, acc=0.995, loss=0.0282]
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:04&lt;00:00,  3.67it/s, acc=0.981, loss=0.0619]
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.93it/s, acc=0.948, loss=0.187]
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.09it/s, acc=0.978, loss=0.115]
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.21it/s, acc=0.983, loss=0.117] 
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.18it/s, acc=0.983, loss=0.0637]
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.22it/s, acc=0.996, loss=0.0414]
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.09it/s, acc=0.987, loss=0.0569]
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.81it/s, acc=0.951, loss=0.246]
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.33it/s, acc=0.978, loss=0.0934]
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.90it/s, acc=0.988, loss=0.0629]
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.59it/s, acc=0.983, loss=0.0716]
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.78it/s, acc=0.994, loss=0.0374]
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.35it/s, acc=0.987, loss=0.0522]
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.14it/s, acc=0.961, loss=0.222]
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  3.99it/s, acc=0.961, loss=0.131]
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.97it/s, acc=0.984, loss=0.0637]
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.40it/s, acc=0.972, loss=0.0873]
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.98it/s, acc=0.988, loss=0.0355]
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.37it/s, acc=0.985, loss=0.0551]
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.20it/s, acc=0.957, loss=0.176]
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.24it/s, acc=0.966, loss=0.142]
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.99it/s, acc=0.99, loss=0.0559] 
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.26it/s, acc=0.976, loss=0.0829]
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.92it/s, acc=0.996, loss=0.0264]
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.46it/s, acc=0.976, loss=0.0747]
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.91it/s, acc=0.949, loss=0.208]
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.40it/s, acc=0.985, loss=0.1]   
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.78it/s, acc=0.986, loss=0.0626]
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.41it/s, acc=0.991, loss=0.0513]
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.85it/s, acc=0.999, loss=0.0268]
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.83it/s, acc=0.994, loss=0.029] 
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.00it/s, acc=0.96, loss=0.165] 
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.20it/s, acc=0.959, loss=0.128]
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.02it/s, acc=0.994, loss=0.0476]
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.32it/s, acc=0.985, loss=0.0628]
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.97it/s, acc=0.997, loss=0.023] 
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.31it/s, acc=0.983, loss=0.0377]
Epoch 1/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.19it/s, acc=0.957, loss=0.169]
Epoch 1/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.03it/s, acc=0.976, loss=0.112]
Epoch 2/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  3.90it/s, acc=0.997, loss=0.0513]
Epoch 2/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.27it/s, acc=0.989, loss=0.0476]
Epoch 3/3 (Training) for EfficientNet_five: 100%|| 30/30 [00:07&lt;00:00,  4.18it/s, acc=0.995, loss=0.0247]
Epoch 3/3 (Validation) for EfficientNet_five: 100%|| 15/15 [00:03&lt;00:00,  4.05it/s, acc=0.994, loss=0.0385]</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Fold 1:
Model saved to EfficientNet_five_model.pth
EfficientNet_five weights saved with best accuracy :0.9290322580645162
Model saved to EfficientNet_five_model.pth
EfficientNet_five weights saved with best accuracy :0.9806451612903225
Model saved to EfficientNet_five_model.pth
EfficientNet_five weights saved with best accuracy :0.9849462365591398
Training completed weight saved.
Fold 2:
weights of EfficientNet_five loaded
Model saved to EfficientNet_five_model.pth
EfficientNet_five weights saved with best accuracy :1.0
Training completed weight saved.
Fold 3:
weights of EfficientNet_five loaded
Training completed weight saved.
-------------------data_class:1 completed---------------
time elapsed:101.01 seconds
Fold 1:
weights of EfficientNet_five loaded
Training completed weight saved.
Fold 2:
weights of EfficientNet_five loaded
Training completed weight saved.
Fold 3:
weights of EfficientNet_five loaded
Training completed weight saved.
-------------------data_class:2 completed---------------
time elapsed:101.50 seconds
Fold 1:
weights of EfficientNet_five loaded
Training completed weight saved.
Fold 2:
weights of EfficientNet_five loaded
Training completed weight saved.
Fold 3:
weights of EfficientNet_five loaded
Training completed weight saved.
-------------------data_class:3 completed---------------
time elapsed:100.93 seconds
Fold 1:
weights of EfficientNet_five loaded
Training completed weight saved.
Fold 2:
weights of EfficientNet_five loaded
Training completed weight saved.
Fold 3:
weights of EfficientNet_five loaded
Training completed weight saved.
-------------------data_class:4 completed---------------
time elapsed:101.68 seconds
Fold 1:
weights of EfficientNet_five loaded
Training completed weight saved.
Fold 2:
weights of EfficientNet_five loaded
Training completed weight saved.
Fold 3:
weights of EfficientNet_five loaded
Training completed weight saved.
-------------------data_class:5 completed---------------
time elapsed:101.88 seconds</code></pre>
</div>
</div>
</section>
<section id="efficientnet-plots-1" class="level1">
<h1>EfficientNet Plots</h1>
<div id="cell-53" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T04:12:52.856228Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T04:12:52.855933Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:12:55.036404Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:12:55.035446Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T04:12:52.856200Z&quot;}" data-trusted="true" data-execution_count="21">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_loss(allloss):</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>        axs[i].plot(np.mean(allloss[<span class="ss">f"fold</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>],axis<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>], label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> fold"</span>,c<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>        axs[i].set_title(<span class="ss">f'Fold </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Validation Mean Loss'</span>)  </span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>        axs[i].set_xlabel(<span class="st">'Epochs/fold'</span>)</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>        axs[i].set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>        axs[i].legend()</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()  </span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_acc(allacc):</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>        axs[i].plot(np.mean(allacc[<span class="ss">f"fold</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>],axis<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>], label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> fold"</span>,c<span class="op">=</span><span class="st">'orange'</span>)</span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>        axs[i].set_title(<span class="ss">f'Fold </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Validation Mean Accuracy'</span>)  </span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>        axs[i].set_xlabel(<span class="st">'Epochs/fold'</span>)</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>        axs[i].set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>        axs[i].legend()</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()  </span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cm(all_y_true, all_y_pred):</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):    </span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>        real <span class="op">=</span> []</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])):</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>            real.extend(ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>][i][<span class="dv">0</span>])</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> []</span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])):</span>
<span id="cb32-35"><a href="#cb32-35" aria-hidden="true" tabindex="-1"></a>            pred.extend(ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>][i][<span class="dv">0</span>])</span>
<span id="cb32-36"><a href="#cb32-36" aria-hidden="true" tabindex="-1"></a>        cm <span class="op">=</span> confusion_matrix(real, pred)</span>
<span id="cb32-37"><a href="#cb32-37" aria-hidden="true" tabindex="-1"></a>        ConfusionMatrixDisplay(cm).plot(ax<span class="op">=</span>axs[fold],cmap<span class="op">=</span><span class="st">'Blues'</span>,values_format<span class="op">=</span><span class="st">'d'</span>)</span>
<span id="cb32-38"><a href="#cb32-38" aria-hidden="true" tabindex="-1"></a>        axs[fold].set_title(<span class="ss">f"Fold </span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb32-39"><a href="#cb32-39" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb32-40"><a href="#cb32-40" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb32-41"><a href="#cb32-41" aria-hidden="true" tabindex="-1"></a>plot_loss(allloss)</span>
<span id="cb32-42"><a href="#cb32-42" aria-hidden="true" tabindex="-1"></a>plot_acc(allacc)</span>
<span id="cb32-43"><a href="#cb32-43" aria-hidden="true" tabindex="-1"></a>plot_cm(ally_true,ally_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-22-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-22-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-22-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="custommodel-2" class="level1">
<h1>CustomModel</h1>
<div id="cell-55" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T04:12:55.037969Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T04:12:55.037640Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:22:28.675499Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:22:28.674317Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T04:12:55.037931Z&quot;}" data-scrolled="true" data-trusted="true" data-execution_count="22">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="co">##</span></span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>allloss <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>allacc <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>ally_true <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>ally_pred <span class="op">=</span> {<span class="st">"fold1"</span>:[],<span class="st">"fold2"</span>:[],<span class="st">"fold3"</span>:[]}</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>metrics <span class="op">=</span> [allloss,allacc,ally_true,ally_pred]</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>timec <span class="op">=</span> []</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>best_acc_cust <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> data_idx <span class="kw">in</span> <span class="bu">range</span>(n_classes):</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> time.time()</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a>    loss,acc,y_true,y_pred,best_acc_cust <span class="op">=</span> one_vs_rest(model,<span class="st">"CustomAttModel_five"</span>,data_idx,best_acc<span class="op">=</span>best_acc_cust)</span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"-------------------data_class:</span><span class="sc">{</span>data_idx<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> completed---------------"</span>)</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"time elapsed:</span><span class="sc">{</span>time<span class="sc">.</span>time()<span class="op">-</span>s<span class="sc">:.2f}</span><span class="ss"> seconds"</span>)</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>    timec.append(time.time()<span class="op">-</span>s)</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>    returned <span class="op">=</span> [loss,acc,y_true,y_pred]</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i,m <span class="kw">in</span> <span class="bu">enumerate</span>(metrics):</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>            m[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>].append(returned[i][<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fold 1:
Model saved to CustomAttModel_five_model.pth
CustomAttModel_five weights saved with best accuracy :0.8623655913978494
Model saved to CustomAttModel_five_model.pth
CustomAttModel_five weights saved with best accuracy :0.967741935483871
Training completed weight saved.
Fold 2:
weights of CustomAttModel_five loaded
Training completed weight saved.
Fold 3:
weights of CustomAttModel_five loaded
Training completed weight saved.
-------------------data_class:1 completed---------------
time elapsed:114.93 seconds
Fold 1:
weights of CustomAttModel_five loaded
Training completed weight saved.
Fold 2:
weights of CustomAttModel_five loaded
Training completed weight saved.
Fold 3:
weights of CustomAttModel_five loaded
Training completed weight saved.
-------------------data_class:2 completed---------------
time elapsed:114.16 seconds
Fold 1:
weights of CustomAttModel_five loaded
Training completed weight saved.
Fold 2:
weights of CustomAttModel_five loaded
Training completed weight saved.
Fold 3:
weights of CustomAttModel_five loaded
Model saved to CustomAttModel_five_model.pth
CustomAttModel_five weights saved with best accuracy :0.9720430107526882
Training completed weight saved.
-------------------data_class:3 completed---------------
time elapsed:114.28 seconds
Fold 1:
weights of CustomAttModel_five loaded
Training completed weight saved.
Fold 2:
weights of CustomAttModel_five loaded
Training completed weight saved.
Fold 3:
weights of CustomAttModel_five loaded
Training completed weight saved.
-------------------data_class:4 completed---------------
time elapsed:115.25 seconds
Fold 1:
weights of CustomAttModel_five loaded
Training completed weight saved.
Fold 2:
weights of CustomAttModel_five loaded
Training completed weight saved.
Fold 3:
weights of CustomAttModel_five loaded
Training completed weight saved.
-------------------data_class:5 completed---------------
time elapsed:115.01 seconds</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.43it/s, acc=0.951, loss=0.196]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.06it/s, acc=0.862, loss=0.315]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.38it/s, acc=0.952, loss=0.178]
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.31it/s, acc=0.968, loss=0.134]
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.53it/s, acc=0.952, loss=0.153]
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.13it/s, acc=0.968, loss=0.125]
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.35it/s, acc=0.961, loss=0.142]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.89it/s, acc=0.953, loss=0.205]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.49it/s, acc=0.961, loss=0.121]
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.88it/s, acc=0.951, loss=0.212]
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.50it/s, acc=0.965, loss=0.122]
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.80it/s, acc=0.951, loss=0.194]
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.57it/s, acc=0.959, loss=0.158]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:04&lt;00:00,  3.70it/s, acc=0.953, loss=0.161]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.41it/s, acc=0.959, loss=0.153]
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.13it/s, acc=0.953, loss=0.176]
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.38it/s, acc=0.959, loss=0.143]
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.87it/s, acc=0.953, loss=0.167]
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.51it/s, acc=0.954, loss=0.174]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.23it/s, acc=0.961, loss=0.151]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.34it/s, acc=0.955, loss=0.157]
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.25it/s, acc=0.961, loss=0.133]
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:09&lt;00:00,  3.31it/s, acc=0.956, loss=0.187]
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.41it/s, acc=0.946, loss=0.157]
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.52it/s, acc=0.961, loss=0.163]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.90it/s, acc=0.948, loss=0.188]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.46it/s, acc=0.96, loss=0.142] 
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.95it/s, acc=0.948, loss=0.169]
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.41it/s, acc=0.961, loss=0.135]
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.23it/s, acc=0.94, loss=0.159] 
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.40it/s, acc=0.955, loss=0.173]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.91it/s, acc=0.961, loss=0.162]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.50it/s, acc=0.955, loss=0.153]
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.75it/s, acc=0.961, loss=0.161]
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.59it/s, acc=0.957, loss=0.145]
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:04&lt;00:00,  3.71it/s, acc=0.946, loss=0.156]
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:09&lt;00:00,  3.21it/s, acc=0.959, loss=0.168]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.98it/s, acc=0.953, loss=0.174]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:09&lt;00:00,  3.33it/s, acc=0.959, loss=0.151]
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.08it/s, acc=0.953, loss=0.179]
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.43it/s, acc=0.959, loss=0.136]
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.07it/s, acc=0.953, loss=0.16] 
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.55it/s, acc=0.962, loss=0.156]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.17it/s, acc=0.946, loss=0.221]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.44it/s, acc=0.962, loss=0.148]
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.94it/s, acc=0.946, loss=0.197]
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.40it/s, acc=0.962, loss=0.14] 
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.03it/s, acc=0.946, loss=0.193]
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.51it/s, acc=0.949, loss=0.187]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.21it/s, acc=0.972, loss=0.127]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.46it/s, acc=0.949, loss=0.168]
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.18it/s, acc=0.972, loss=0.12]  
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.50it/s, acc=0.949, loss=0.165]
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.22it/s, acc=0.972, loss=0.112]
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.48it/s, acc=0.957, loss=0.165]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.09it/s, acc=0.957, loss=0.161]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.53it/s, acc=0.957, loss=0.152]
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.05it/s, acc=0.957, loss=0.175]
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.41it/s, acc=0.957, loss=0.141]
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.22it/s, acc=0.957, loss=0.143]
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.36it/s, acc=0.963, loss=0.145]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:04&lt;00:00,  3.73it/s, acc=0.944, loss=0.183]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.38it/s, acc=0.963, loss=0.135]
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.79it/s, acc=0.944, loss=0.173]
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.55it/s, acc=0.963, loss=0.134]
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.15it/s, acc=0.944, loss=0.171]
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:09&lt;00:00,  3.30it/s, acc=0.951, loss=0.181]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.94it/s, acc=0.97, loss=0.125] 
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.48it/s, acc=0.952, loss=0.158]
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.79it/s, acc=0.97, loss=0.126] 
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.46it/s, acc=0.951, loss=0.157]
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:04&lt;00:00,  3.68it/s, acc=0.97, loss=0.12]  
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:09&lt;00:00,  3.30it/s, acc=0.955, loss=0.174]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.22it/s, acc=0.961, loss=0.144]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.52it/s, acc=0.956, loss=0.147]
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.89it/s, acc=0.961, loss=0.126]
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.50it/s, acc=0.957, loss=0.139] 
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  4.03it/s, acc=0.968, loss=0.109] 
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.37it/s, acc=0.965, loss=0.149]
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.93it/s, acc=0.942, loss=0.226]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.47it/s, acc=0.965, loss=0.137]
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.89it/s, acc=0.942, loss=0.194]
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.52it/s, acc=0.962, loss=0.116]
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:04&lt;00:00,  3.73it/s, acc=0.944, loss=0.169]
Epoch 1/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.54it/s, acc=0.952, loss=0.18] 
Epoch 1/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.88it/s, acc=0.968, loss=0.136]
Epoch 2/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.48it/s, acc=0.949, loss=0.16] 
Epoch 2/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:03&lt;00:00,  3.90it/s, acc=0.935, loss=0.211]
Epoch 3/3 (Training) for CustomAttModel_five: 100%|| 30/30 [00:08&lt;00:00,  3.45it/s, acc=0.953, loss=0.146]
Epoch 3/3 (Validation) for CustomAttModel_five: 100%|| 15/15 [00:04&lt;00:00,  3.64it/s, acc=0.968, loss=0.125]</code></pre>
</div>
</div>
</section>
<section id="custommodel-plots-1" class="level1">
<h1>CustomModel Plots</h1>
<div id="cell-57" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T04:22:28.677844Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T04:22:28.677435Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:22:30.756484Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:22:30.755523Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T04:22:28.677804Z&quot;}" data-trusted="true" data-execution_count="23">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_loss(allloss):</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>        axs[i].plot(np.mean(allloss[<span class="ss">f"fold</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>],axis<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>], label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> fold"</span>,c<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>        axs[i].set_title(<span class="ss">f'Fold </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Validation Mean Loss'</span>)  </span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>        axs[i].set_xlabel(<span class="st">'Epochs/fold'</span>)</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>        axs[i].set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>        axs[i].legend()</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()  </span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_acc(allacc):</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>        axs[i].plot(np.mean(allacc[<span class="ss">f"fold</span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>],axis<span class="op">=</span><span class="dv">0</span>)[<span class="dv">0</span>], label<span class="op">=</span><span class="ss">f"</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> fold"</span>,c<span class="op">=</span><span class="st">'orange'</span>)</span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>        axs[i].set_title(<span class="ss">f'Fold </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss"> Validation Mean Accuracy'</span>)  </span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>        axs[i].set_xlabel(<span class="st">'Epochs/fold'</span>)</span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>        axs[i].set_ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>        axs[i].legend()</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()  </span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_cm(all_y_true, all_y_pred):</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>    fig, axs <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span>))</span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> fold <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">3</span>):    </span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>        real <span class="op">=</span> []</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])):</span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a>            real.extend(ally_true[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>][i][<span class="dv">0</span>])</span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a>        pred <span class="op">=</span> []</span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>])):</span>
<span id="cb36-35"><a href="#cb36-35" aria-hidden="true" tabindex="-1"></a>            pred.extend(ally_pred[<span class="ss">f"fold</span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>][i][<span class="dv">0</span>])</span>
<span id="cb36-36"><a href="#cb36-36" aria-hidden="true" tabindex="-1"></a>        cm <span class="op">=</span> confusion_matrix(real, pred)</span>
<span id="cb36-37"><a href="#cb36-37" aria-hidden="true" tabindex="-1"></a>        ConfusionMatrixDisplay(cm).plot(ax<span class="op">=</span>axs[fold],cmap<span class="op">=</span><span class="st">'Blues'</span>,values_format<span class="op">=</span><span class="st">'d'</span>)</span>
<span id="cb36-38"><a href="#cb36-38" aria-hidden="true" tabindex="-1"></a>        axs[fold].set_title(<span class="ss">f"Fold </span><span class="sc">{</span>fold<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb36-39"><a href="#cb36-39" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb36-40"><a href="#cb36-40" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb36-41"><a href="#cb36-41" aria-hidden="true" tabindex="-1"></a>plot_loss(allloss)</span>
<span id="cb36-42"><a href="#cb36-42" aria-hidden="true" tabindex="-1"></a>plot_acc(allacc)</span>
<span id="cb36-43"><a href="#cb36-43" aria-hidden="true" tabindex="-1"></a>plot_cm(ally_true,ally_pred)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-24-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-24-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-24-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="best-accuracy-on-validation" class="level1">
<h1>Best Accuracy on Validation</h1>
<div id="cell-59" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T04:22:30.758002Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T04:22:30.757719Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:22:31.190238Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:22:31.189289Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T04:22:30.757977Z&quot;}" data-trusted="true" data-execution_count="24">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> [<span class="st">"resnet"</span>, <span class="st">"efficientnet"</span>, <span class="st">"custom"</span>]</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>accuracies <span class="op">=</span> [best_acc_resnet, best_acc_eff, best_acc_cust]</span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a colormap</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">"orange"</span>,<span class="st">"blue"</span>,<span class="st">"red"</span>]</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> plt.bar(models, accuracies, color<span class="op">=</span>colors)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Models'</span>)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Accuracy Comparison of Different Models'</span>)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Adding the accuracy values on top of the bars</span></span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bar, accuracy <span class="kw">in</span> <span class="bu">zip</span>(bars, accuracies):</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>    plt.text(bar.get_x() <span class="op">+</span> bar.get_width() <span class="op">/</span> <span class="dv">2</span>, bar.get_height() <span class="op">+</span> <span class="fl">0.005</span>, <span class="ss">f'</span><span class="sc">{</span>accuracy<span class="sc">:.2f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-25-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="time-taken-1" class="level1">
<h1>Time Taken</h1>
<div id="cell-61" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T04:22:31.192010Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T04:22:31.191660Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:22:31.396929Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:22:31.396029Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T04:22:31.191978Z&quot;}" data-trusted="true" data-execution_count="25">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> [<span class="st">"resnet"</span>, <span class="st">"efficientnet"</span>, <span class="st">"custom"</span>]</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>time <span class="op">=</span> [np.<span class="bu">sum</span>(timer), np.<span class="bu">sum</span>(timee), np.<span class="bu">sum</span>(timec)]</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a colormap</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">"orange"</span>,<span class="st">"blue"</span>,<span class="st">"red"</span>]</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> plt.bar(models, time, color<span class="op">=</span>colors)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Models'</span>)</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Time in Seconds'</span>)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Time taken for Different Models'</span>)</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bar, time <span class="kw">in</span> <span class="bu">zip</span>(bars, time):</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>    plt.text(bar.get_x() <span class="op">+</span> bar.get_width() <span class="op">/</span> <span class="dv">2</span>, bar.get_height() <span class="op">+</span> <span class="fl">0.005</span>, <span class="ss">f'</span><span class="sc">{</span>time<span class="sc">:.2f}</span><span class="ss">'</span>, ha<span class="op">=</span><span class="st">'center'</span>, va<span class="op">=</span><span class="st">'bottom'</span>)</span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-26-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="visualising-neural-nets" class="level1">
<h1>Visualising Neural Nets</h1>
<section id="visualising-customnet-attention-map" class="level2">
<h2 class="anchored" data-anchor-id="visualising-customnet-attention-map">Visualising CustomNet Attention Map</h2>
<div id="cell-64" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T04:22:31.398652Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T04:22:31.398277Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:22:31.622419Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:22:31.621538Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T04:22:31.398608Z&quot;}" data-trusted="true" data-execution_count="26">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Attn(Model):</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(num_classes<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>        block1 <span class="op">=</span> <span class="va">self</span>.conv_block1(x)       <span class="co"># /2</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>        block2 <span class="op">=</span> <span class="va">self</span>.conv_block2(block1)  <span class="co"># /4</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>        block3 <span class="op">=</span> <span class="va">self</span>.conv_block3(block2)  <span class="co"># /8</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>        block4 <span class="op">=</span> <span class="va">self</span>.conv_block4(block3)  <span class="co"># /16</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>        block5 <span class="op">=</span> <span class="va">self</span>.conv_block5(block4)  <span class="co"># /32</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>        N, __, __, __ <span class="op">=</span> block5.size()</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>        g <span class="op">=</span> <span class="va">self</span>.pool(block5).view(N, <span class="dv">512</span>)</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>        a1, g1 <span class="op">=</span> <span class="va">self</span>.attn1(block3, block5)</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a>        g_hat <span class="op">=</span> torch.cat((g, g1), dim<span class="op">=</span><span class="dv">1</span>)  <span class="co"># batch_size x C</span></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.cls(g_hat)</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> a1</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Attn().to(device)</span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>model.load_state_dict(torch.load(<span class="ss">f"CustomAttModel_bi_model.pth"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>&lt;All keys matched successfully&gt;</code></pre>
</div>
</div>
<div id="cell-65" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T04:22:31.624456Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T04:22:31.623806Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:22:33.802410Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:22:33.801346Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T04:22:31.624419Z&quot;}" data-trusted="true" data-execution_count="27">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>random_indices <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">90</span>, size<span class="op">=</span><span class="dv">16</span>)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">4</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">8</span>))</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot each attention map</span></span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, ax <span class="kw">in</span> <span class="bu">enumerate</span>(axes.flatten()):</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>        img_tensor <span class="op">=</span> temp_data[random_indices[i]][<span class="dv">0</span>].unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>        attention_map <span class="op">=</span> model(img_tensor).cpu().numpy()</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>    ax.imshow(attention_map[<span class="dv">0</span>][<span class="dv">0</span>])</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb41-15"><a href="#cb41-15" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-28-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="visualing-convolution-output-of-layers" class="level2">
<h2 class="anchored" data-anchor-id="visualing-convolution-output-of-layers">Visualing Convolution Output of Layers</h2>
<div id="cell-67" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T04:22:33.808668Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T04:22:33.808196Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:22:33.823864Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:22:33.822948Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T04:22:33.808635Z&quot;}" data-trusted="true" data-execution_count="28">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> layer_viz(model, input_image_path):</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Load the image and preprocess it</span></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>        transforms.Resize(<span class="dv">256</span>),</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>        transforms.CenterCrop(<span class="dv">224</span>),</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize(mean<span class="op">=</span>[<span class="fl">0.485</span>, <span class="fl">0.456</span>, <span class="fl">0.406</span>], std<span class="op">=</span>[<span class="fl">0.229</span>, <span class="fl">0.224</span>, <span class="fl">0.225</span>]),</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>    ])</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>    input_image <span class="op">=</span> Image.<span class="bu">open</span>(input_image_path)</span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>    input_tensor <span class="op">=</span> transform(input_image).unsqueeze(<span class="dv">0</span>).to(device)  <span class="co"># Add batch dimension</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Set model to evaluation mode</span></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Forward pass to get the output of convolutional layers</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>    activations <span class="op">=</span> []</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> hook(module, <span class="bu">input</span>, output):</span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>        activations.append(output.cpu().numpy())</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a>    hooks <span class="op">=</span> []</span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> layer <span class="kw">in</span> model.modules():</span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">isinstance</span>(layer, torch.nn.Conv2d):</span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>            hooks.append(layer.register_forward_hook(hook))</span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Pass input image through the model</span></span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a>        model(input_tensor)</span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a>    activations <span class="op">=</span> activations[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Remove hooks</span></span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> hook <span class="kw">in</span> hooks:</span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a>        hook.remove()</span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot the activations of each convolutional layer in subplots</span></span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a>    num_layers <span class="op">=</span> <span class="bu">len</span>(activations)</span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a>    num_cols <span class="op">=</span> <span class="bu">min</span>(num_layers, <span class="dv">4</span>)  <span class="co"># Limit the number of columns in subplots</span></span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a>    num_rows <span class="op">=</span> (num_layers <span class="op">-</span> <span class="dv">1</span>) <span class="op">//</span> num_cols <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a>    fig, axes <span class="op">=</span> plt.subplots(num_rows, num_cols, figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">5</span> <span class="op">*</span> num_rows))</span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, activation <span class="kw">in</span> <span class="bu">enumerate</span>(activations):</span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a>        row_idx <span class="op">=</span> i <span class="op">//</span> num_cols</span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a>        col_idx <span class="op">=</span> i <span class="op">%</span> num_cols</span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a>        axes[row_idx, col_idx].imshow(activation[<span class="dv">0</span>][<span class="dv">0</span>].squeeze(), cmap<span class="op">=</span><span class="st">'viridis'</span>)</span>
<span id="cb42-44"><a href="#cb42-44" aria-hidden="true" tabindex="-1"></a>        axes[row_idx, col_idx].set_title(<span class="ss">f'Layer </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb42-45"><a href="#cb42-45" aria-hidden="true" tabindex="-1"></a>        axes[row_idx, col_idx].axis(<span class="st">'off'</span>)</span>
<span id="cb42-46"><a href="#cb42-46" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb42-47"><a href="#cb42-47" aria-hidden="true" tabindex="-1"></a>    plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="resnet-2" class="level1">
<h1>Resnet</h1>
<div id="cell-69" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T04:22:33.825156Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T04:22:33.824827Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:22:35.908742Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:22:35.907818Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T04:22:33.825124Z&quot;}" data-trusted="true" data-execution_count="29">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>resnet <span class="op">=</span> torch.hub.load(<span class="st">'pytorch/vision:v0.10.0'</span>, <span class="st">'resnet18'</span>, pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>resnet.fc <span class="op">=</span> nn.Linear(<span class="dv">512</span>,<span class="dv">5</span>)</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>resnet.to(device)</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>resnet.load_state_dict(torch.load(<span class="ss">f"Resnet_five_model.pth"</span>))</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Usage example:</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>layer_viz(resnet, input_image_path<span class="op">=</span><span class="st">"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals/antelope/02f4b3be2d.jpg"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0
/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-30-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="efficientnet-1" class="level1">
<h1>EfficientNet</h1>
<div id="cell-71" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T04:22:35.910258Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T04:22:35.909966Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:22:38.118113Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:22:38.117273Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T04:22:35.910233Z&quot;}" data-trusted="true" data-execution_count="30">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>efficientnet <span class="op">=</span> torchvision.models.efficientnet_b0(pretrained<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>efficientnet.classifier[<span class="dv">1</span>] <span class="op">=</span> nn.Linear(<span class="dv">1280</span>,<span class="dv">5</span>)</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>efficientnet.to(device)</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>efficientnet.load_state_dict(torch.load(<span class="st">"EfficientNet_five_model.pth"</span>))</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>layer_viz(resnet, input_image_path<span class="op">=</span><span class="st">"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals/antelope/02f4b3be2d.jpg"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-31-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<section id="custommodel-3" class="level2">
<h2 class="anchored" data-anchor-id="custommodel-3">CustomModel</h2>
<div id="cell-73" class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2024-02-23T04:22:38.119650Z&quot;,&quot;iopub.status.busy&quot;:&quot;2024-02-23T04:22:38.119353Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-02-23T04:22:40.097910Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-02-23T04:22:40.096995Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-02-23T04:22:38.119625Z&quot;}" data-trusted="true" data-execution_count="31">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Model(<span class="dv">2</span>).to(device)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>model.load_state_dict(torch.load(<span class="ss">f"CustomAttModel_bi_model.pth"</span>))</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>layer_viz(resnet, input_image_path<span class="op">=</span><span class="st">"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals/antelope/02f4b3be2d.jpg"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="ml-for-sustainability-srip-2024_files/figure-html/cell-32-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="double-descent-for-custommodel-performance" class="level2">
<h2 class="anchored" data-anchor-id="double-descent-for-custommodel-performance">Double Descent for custommodel performance</h2>
<ul>
<li>in othermodels loss and accuracy is as expected.</li>
<li>but in CustomAttentionModel accuracy is first increasing then decreasing due to generalisation error but if we see on fold 3 it is again increasing. it can be explained with <strong>Double Descent</strong> it is <strong>counter intuitive</strong> pattern observed, when in over parametrised models generalisation error increases after overfitting.</li>
</ul>
<p>ref:[https://mlu-explain.github.io/double-descent/]</p>
</section>
<section id="layer-outputs" class="level2">
<h2 class="anchored" data-anchor-id="layer-outputs">layer outputs</h2>
<ul>
<li>Convolution is our prior knowledge inserted into neural nets that pixels are dependent around its neighbours.but we dont define how it is related and it is learned.</li>
<li>each layer is like a building block of images of evolving hierachy, where first learn lines and edges then laters comple features like face and eye.</li>
</ul>
</section>
</section>
<section id="additional-refrences" class="level1">
<h1>Additional Refrences</h1>
</section>
<section id="httpsgithub.comautobot37machinelearningengine-for-training-code" class="level1">
<h1>https://github.com/Autobot37/MachineLearningEngine for training code</h1>
</section>
<section id="spcom2024-paperid204-code-i-am-2nd-author" class="level1">
<h1>SPCOM2024 PaperID204 code [i am 2nd author]</h1>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<footer class="footer"><div class="nav-footer"><div class="nav-footer-center"><div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/Autobot37/imageclassify/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></div></div></footer></body></html>